{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "\n",
    "def calculate_metrics(true_values, pred_values):\n",
    "    mse = round(mean_squared_error(true_values, pred_values),3)\n",
    "    mae = round(mean_absolute_error(true_values, pred_values),3)\n",
    "    r_score = round(r2_score(true_values, pred_values),3)\n",
    "\n",
    "    return {\"mse\": mse,\n",
    "            \"mae\": mae,\n",
    "            \"r^2\": r_score,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 21.0.1+12-LTS-29, mixed mode, sharing)\n",
      "  Starting server from C:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\38066\\AppData\\Local\\Temp\\tmppe9sd56n\n",
      "  JVM stdout: C:\\Users\\38066\\AppData\\Local\\Temp\\tmppe9sd56n\\h2o_38066_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\38066\\AppData\\Local\\Temp\\tmppe9sd56n\\h2o_38066_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n",
      "Warning: Your H2O cluster version is (3 months and 26 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Kiev</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.44.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>3 months and 26 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_38066_9sfjj2</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.952 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.9 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       Europe/Kiev\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.44.0.3\n",
       "H2O_cluster_version_age:    3 months and 26 days\n",
       "H2O_cluster_name:           H2O_from_python_38066_9sfjj2\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.952 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.9 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# Start the H2O cluster (locally)\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "183\n",
      "['f_freedom', 'distance_between_atoms_in_cycle_and_f_group', 'PPSA5', 'mol_num_cycles', 'nFRing', 'nAHRing', 'angle_R1X1R2', 'nF', 'identificator', 'mol_weight', 'dipole_moment', 'nHRing', 'nO', 'PBF', 'nC', 'angle_X2X1R1', 'nARing', 'angle_R2X2R1', 'cis/trans', 'PNSA5', 'FPSA3', 'naRing', 'tpsa+f', 'mol_volume', 'RPCS', 'f_atom_fraction', 'GeomShapeIndex', 'WPSA5', 'TASA', 'f_to_fg', 'dihedral_angle', 'nFARing', 'distance_between_atoms_in_f_group_centers', 'avg_atoms_in_cycle', 'angle_X1X2R2', 'nFHRing', 'nFAHRing', 'chirality', 'pKa', 'logP']\n",
      "mol_volume outliers indexes: [127]\n",
      "f_atom_fraction outliers indexes: [124]\n",
      "distance_between_atoms_in_f_group_centers outliers indexes: [ 35 167]\n",
      "logP outliers indexes: [82, 83]\n",
      "Remains rows:172, amount of features: 40\n",
      "147 25\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname('C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\ml_part'))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ml_part.random_forest.data_prep.preparation import DataPreparation\n",
    "from ml_part.random_forest.train import RFTrain\n",
    "\n",
    "CSV_PATH = r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\updated_features\\remained_features_logP_08.02_v4_fixed_distances_chirality.csv'\n",
    "smiles_filepath = r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\updated_features\\smiles_to_index.pkl'\n",
    "\n",
    "dataPreparation = DataPreparation(CSV_PATH)\n",
    "\n",
    "unimportant_features_to_drop = ['dipole_moment']\n",
    "X, y = dataPreparation.prepare_data_for_RF(is_pKa=False,\n",
    "                                           use_mandatory_features=True,\n",
    "                                           is_remove_outliers=True,\n",
    "                                           is_remove_nan=False,\n",
    "                                           outliers_features_to_skip=unimportant_features_to_drop)\n",
    "\n",
    "LOGP_FEATURES = ['f_freedom', 'PPSA5', 'mol_num_cycles', 'nFRing', 'nF', 'identificator', 'f_atom_fraction',\n",
    "                 'mol_weight', 'dipole_moment', 'nHRing', 'nO', 'PBF', 'nC', 'nARing',\n",
    "                 'cis/trans', 'PNSA5', 'FPSA3', 'mol_volume', 'RPCS', 'GeomShapeIndex',\n",
    "                 'WPSA5', 'TASA', 'f_to_fg', 'avg_atoms_in_cycle', 'nFHRing',\n",
    "                 'chirality']\n",
    "\n",
    "features_to_drop = []\n",
    "for feature_name in X.columns:\n",
    "    if feature_name not in LOGP_FEATURES:\n",
    "        features_to_drop.append(feature_name)\n",
    "\n",
    "\n",
    "X = X.drop(features_to_drop, axis=1)\n",
    "\n",
    "rf_train = RFTrain(X=X, \n",
    "                   y=y,\n",
    "                   smiles_filepath=smiles_filepath,\n",
    "                   is_pKa=False,\n",
    "                   k_folds=2)\n",
    "\n",
    "y_train = rf_train.y_train\n",
    "X_train = rf_train.X_train\n",
    "\n",
    "y_test = rf_train.y_test\n",
    "X_test = rf_train.X_test\n",
    "\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "print(len(train_df), len(test_df))\n",
    "\n",
    "train = h2o.H2OFrame(train_df)\n",
    "test = h2o.H2OFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f_freedom', 'PPSA5', 'mol_num_cycles', 'nFRing', 'nF', 'identificator',\n",
       "       'mol_weight', 'dipole_moment', 'nHRing', 'nO', 'PBF', 'nC', 'nARing',\n",
       "       'cis/trans', 'PNSA5', 'FPSA3', 'mol_volume', 'RPCS', 'f_atom_fraction',\n",
       "       'GeomShapeIndex', 'WPSA5', 'TASA', 'f_to_fg', 'avg_atoms_in_cycle',\n",
       "       'nFHRing', 'chirality', 'logP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nHRing, nARing, corr: 0.6568999956701997\n",
      "nHRing, nFRing, corr: 0.5799472743597861\n",
      "nHRing, nFHRing, corr: 0.7298992678284247\n",
      "nARing, nHRing, corr: 0.6568999956701996\n",
      "nARing, nFRing, corr: 0.8557878388867258\n",
      "nARing, nFHRing, corr: 0.7758976171502688\n",
      "nFRing, nHRing, corr: 0.5799472743597861\n",
      "nFRing, nARing, corr: 0.8557878388867258\n",
      "nFRing, nFHRing, corr: 0.8090152479786314\n",
      "nFHRing, nHRing, corr: 0.7298992678284247\n",
      "nFHRing, nARing, corr: 0.775897617150269\n",
      "nFHRing, nFRing, corr: 0.8090152479786314\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "\n",
    "def cramers_v(confusion_matrix):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher,\n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))\n",
    "    rcorr = r - ((r - 1) ** 2) / (n - 1)\n",
    "    kcorr = k - ((k - 1) ** 2) / (n - 1)\n",
    "    return np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))\n",
    "\n",
    "\n",
    "ring_features = [feature_name for feature_name in X.columns if 'ring' in feature_name.lower()]\n",
    "ring_features_to_remain = ['nFRing', 'nHRing', 'nARing', 'nFHRing']\n",
    "\n",
    "for i in range(len(ring_features)):\n",
    "    for j in range(len(ring_features)):\n",
    "        first_feature = X[ring_features[i]]\n",
    "        second_feature = X[ring_features[j]]\n",
    "\n",
    "        if i == j:\n",
    "            continue\n",
    "\n",
    "        confusion_matrix = pd.crosstab(first_feature, second_feature)\n",
    "        cramers_v_value = cramers_v(confusion_matrix.values)\n",
    "        print(f\"{ring_features[i]}, {ring_features[j]}, corr: {cramers_v_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "13:02:02.590: Fold column fold_id will be used for cross-validation. nfolds parameter will be ignored.\n",
      "13:02:02.590: AutoML: XGBoost is not available; skipping it.\n",
      "13:02:02.642: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 147.0.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "model_id                                                     rmse        mse       mae      rmsle    mean_residual_deviance\n",
      "StackedEnsemble_BestOfFamily_5_AutoML_2_20240416_130202  0.242794  0.058949   0.188629  0.0859053                 0.058949\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_31    0.244786  0.0599202  0.190748  0.0876398                 0.0599202\n",
      "StackedEnsemble_BestOfFamily_1_AutoML_2_20240416_130202  0.245358  0.0602006  0.187299  0.0858583                 0.0602006\n",
      "GLM_1_AutoML_2_20240416_130202                           0.245511  0.0602757  0.189919  0.086001                  0.0602757\n",
      "StackedEnsemble_AllModels_1_AutoML_2_20240416_130202     0.246037  0.0605341  0.187939  0.0860266                 0.0605341\n",
      "StackedEnsemble_BestOfFamily_2_AutoML_2_20240416_130202  0.246414  0.0607199  0.188506  0.0862328                 0.0607199\n",
      "StackedEnsemble_AllModels_2_AutoML_2_20240416_130202     0.246629  0.0608261  0.189203  0.0862272                 0.0608261\n",
      "StackedEnsemble_BestOfFamily_3_AutoML_2_20240416_130202  0.248723  0.0618633  0.193738  0.0884754                 0.0618633\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_44    0.24895   0.0619763  0.192516  0.088058                  0.0619763\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_54    0.24978   0.0623901  0.197701  0.0912603                 0.0623901\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_252   0.251014  0.0630082  0.193701  0.0924382                 0.0630082\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_18    0.251422  0.063213   0.197794  0.0895905                 0.063213\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_35    0.251971  0.0634892  0.199487  0.0918073                 0.0634892\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_52    0.25229   0.0636503  0.194987  0.0915087                 0.0636503\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_17    0.254556  0.0647986  0.194992  0.0929324                 0.0647986\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_120   0.254653  0.0648481  0.196794  0.0915982                 0.0648481\n",
      "StackedEnsemble_AllModels_6_AutoML_2_20240416_130202     0.254745  0.0648951  0.196823  0.0906393                 0.0648951\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_5     0.255661  0.0653623  0.194505  0.0921351                 0.0653623\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_24    0.256035  0.0655537  0.194307  0.0937077                 0.0655537\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_260   0.256973  0.066035   0.200476  0.092555                  0.066035\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_106   0.258296  0.0667171  0.201399  0.0911784                 0.0667171\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_81    0.258825  0.0669905  0.204327  0.0928442                 0.0669905\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_119   0.259095  0.0671304  0.199389  0.0911333                 0.0671304\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_74    0.259608  0.0673962  0.20397   0.0917344                 0.0673962\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_263   0.260332  0.0677727  0.205565  0.0930642                 0.0677727\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_110   0.260593  0.0679088  0.203543  0.0944605                 0.0679088\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_114   0.260712  0.0679709  0.202487  0.0942746                 0.0679709\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_2     0.260767  0.0679993  0.202603  0.0920006                 0.0679993\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_33    0.260773  0.0680027  0.200914  0.0894339                 0.0680027\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_259   0.260849  0.068042   0.201272  0.0969309                 0.068042\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_6     0.260969  0.0681047  0.203458  0.0939796                 0.0681047\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_51    0.261584  0.0684263  0.202728  0.0950298                 0.0684263\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_61    0.261759  0.068518   0.2047    0.0959676                 0.068518\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_20    0.262298  0.0688     0.203849  0.0960189                 0.0688\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_97    0.262744  0.0690346  0.198169  0.0965069                 0.0690346\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_48    0.262847  0.0690884  0.202717  0.0948198                 0.0690884\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_247   0.262944  0.0691395  0.204575  0.0931867                 0.0691395\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_105   0.26324   0.0692954  0.199213  0.0966809                 0.0692954\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_250   0.263736  0.0695568  0.207692  0.0953838                 0.0695568\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_88    0.264022  0.0697075  0.210488  0.0980951                 0.0697075\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_13    0.264482  0.0699506  0.206322  0.0965628                 0.0699506\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_19    0.264583  0.0700042  0.199808  0.0965024                 0.0700042\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_59    0.265411  0.0704431  0.212785  0.0953424                 0.0704431\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_49    0.266146  0.0708337  0.204337  0.0953637                 0.0708337\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_92    0.266648  0.0711009  0.207763  0.0958972                 0.0711009\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_50    0.266655  0.0711048  0.208339  0.0978733                 0.0711048\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_66    0.266708  0.071133   0.21369   0.094089                  0.071133\n",
      "StackedEnsemble_AllModels_5_AutoML_2_20240416_130202     0.267307  0.0714531  0.205204  0.0951889                 0.0714531\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_111   0.267709  0.0716683  0.20942   0.0980317                 0.0716683\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_32    0.268811  0.0722593  0.202608  0.0964711                 0.0722593\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_245   0.268845  0.0722777  0.214304  0.0977595                 0.0722777\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_11    0.268911  0.0723132  0.214902  0.0946943                 0.0723132\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_14    0.268939  0.0723282  0.209323  0.0954813                 0.0723282\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_40    0.26906   0.0723935  0.210675  0.0979046                 0.0723935\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_89    0.269243  0.072492   0.212438  0.0993707                 0.072492\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_67    0.269847  0.0728177  0.200982  0.097646                  0.0728177\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_38    0.269864  0.0728264  0.214719  0.0983303                 0.0728264\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_68    0.270381  0.0731059  0.214718  0.0969315                 0.0731059\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_1              0.270389  0.0731104  0.208416  0.0963464                 0.0731104\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_255   0.270848  0.0733588  0.213715  0.0995813                 0.0733588\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_246   0.270877  0.0733745  0.205082  0.0993992                 0.0733745\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_84    0.271329  0.0736194  0.209355  0.095754                  0.0736194\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_79    0.271508  0.0737164  0.211799  0.0992888                 0.0737164\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_103   0.27178   0.0738643  0.207716  0.0975202                 0.0738643\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_22    0.271803  0.0738768  0.209878  0.0971135                 0.0738768\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_486            0.271879  0.0739183  0.206764  0.0951576                 0.0739183\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_659            0.272126  0.0740525  0.211329  0.0960314                 0.0740525\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_254   0.27252   0.074267   0.211727  0.0990841                 0.074267\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_80    0.273282  0.0746833  0.219107  0.099528                  0.0746833\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_41    0.27364   0.0748787  0.212995  0.102404                  0.0748787\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_27    0.275069  0.0756631  0.212113  0.100315                  0.0756631\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_116   0.275144  0.0757042  0.206042  0.100791                  0.0757042\n",
      "StackedEnsemble_BestOfFamily_4_AutoML_2_20240416_130202  0.275228  0.0757507  0.210582  0.0938102                 0.0757507\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_78    0.275672  0.0759951  0.201304  0.0993275                 0.0759951\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_584            0.276249  0.0763137  0.215925  0.0981179                 0.0763137\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_29    0.276344  0.0763659  0.210064  0.10163                   0.0763659\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_729            0.276482  0.0764421  0.208475  0.100032                  0.0764421\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_644            0.2765    0.0764524  0.207041  0.0975482                 0.0764524\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_46    0.276644  0.0765317  0.220176  0.0995496                 0.0765317\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_185            0.277175  0.0768258  0.212432  0.0985989                 0.0768258\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_12    0.277183  0.0768301  0.218673  0.10036                   0.0768301\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_233            0.277288  0.0768887  0.208917  0.0969865                 0.0768887\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_113   0.277875  0.0772144  0.207961  0.100472                  0.0772144\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_727            0.277995  0.0772812  0.216913  0.098651                  0.0772812\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_619            0.27822   0.0774064  0.214246  0.0986911                 0.0774064\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_284            0.278852  0.0777586  0.214765  0.098341                  0.0777586\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_36    0.279063  0.077876   0.215375  0.0978023                 0.077876\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_39    0.279086  0.0778889  0.216664  0.0989018                 0.0778889\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_241   0.279107  0.0779007  0.214956  0.103243                  0.0779007\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_12    0.279149  0.0779241  0.212869  0.100467                  0.0779241\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_577            0.279271  0.0779922  0.217228  0.0990189                 0.0779922\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_100   0.279412  0.0780713  0.215914  0.103222                  0.0780713\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_804            0.279446  0.0780899  0.216863  0.0985925                 0.0780899\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_557            0.279787  0.078281   0.215748  0.0986641                 0.078281\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_639            0.279891  0.078339   0.211395  0.0990192                 0.078339\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_512            0.280099  0.0784557  0.216308  0.0979539                 0.0784557\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_414            0.280113  0.0784634  0.216196  0.0981286                 0.0784634\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_714            0.280175  0.0784982  0.223669  0.0998453                 0.0784982\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_37             0.280195  0.0785092  0.223351  0.0993932                 0.0785092\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_376            0.280323  0.0785811  0.218669  0.0974035                 0.0785811\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_431            0.280348  0.0785949  0.215391  0.0987666                 0.0785949\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_75    0.280432  0.0786424  0.221223  0.0997742                 0.0786424\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_244   0.280487  0.0786728  0.22049   0.099309                  0.0786728\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_26    0.280507  0.0786843  0.208678  0.10152                   0.0786843\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_784            0.280811  0.0788549  0.208062  0.099538                  0.0788549\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_560            0.280969  0.0789433  0.216408  0.099552                  0.0789433\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_743            0.280981  0.0789502  0.217315  0.0994389                 0.0789502\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_184            0.281015  0.0789695  0.218638  0.0991692                 0.0789695\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_458            0.281111  0.0790235  0.212489  0.0987899                 0.0790235\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_669            0.281298  0.0791283  0.21752   0.0992134                 0.0791283\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_25    0.281392  0.0791814  0.221538  0.101811                  0.0791814\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_26    0.281533  0.0792606  0.219838  0.102526                  0.0792606\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_411            0.281724  0.0793685  0.215051  0.0997041                 0.0793685\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_1     0.281735  0.0793746  0.213657  0.102336                  0.0793746\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_327            0.281802  0.0794126  0.212009  0.0992277                 0.0794126\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_253   0.281934  0.0794867  0.208683  0.0957125                 0.0794867\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_173            0.281957  0.0794997  0.213814  0.0992164                 0.0794997\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_645            0.281986  0.0795159  0.218221  0.0985291                 0.0795159\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_812            0.282137  0.0796013  0.21771   0.0988968                 0.0796013\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_434            0.282226  0.0796517  0.219106  0.0988512                 0.0796517\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_380            0.282267  0.0796745  0.21389   0.0999023                 0.0796745\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_257            0.282296  0.079691   0.218173  0.0998983                 0.079691\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_108   0.282335  0.0797128  0.214362  0.102158                  0.0797128\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_595            0.282341  0.0797163  0.211093  0.0995285                 0.0797163\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_697            0.282357  0.0797254  0.213734  0.100114                  0.0797254\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_8     0.282365  0.0797301  0.221022  0.104098                  0.0797301\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_454            0.282512  0.0798133  0.209742  0.0989016                 0.0798133\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_3              0.282588  0.0798559  0.216123  0.0988172                 0.0798559\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_795            0.282651  0.0798917  0.21773   0.0989216                 0.0798917\n",
      "StackedEnsemble_AllModels_4_AutoML_2_20240416_130202     0.282848  0.0800032  0.215229  0.101164                  0.0800032\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_617            0.282899  0.080032   0.21293   0.0997212                 0.080032\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_323            0.283013  0.0800961  0.215844  0.0993047                 0.0800961\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_773            0.283023  0.0801021  0.214438  0.0993725                 0.0801021\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_355            0.28307   0.0801288  0.22016   0.0995404                 0.0801288\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_15    0.283113  0.0801529  0.217167  0.103155                  0.0801529\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_63    0.283177  0.0801891  0.226872  0.107614                  0.0801891\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_451            0.283236  0.0802226  0.218525  0.0994409                 0.0802226\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_32             0.283271  0.0802427  0.218794  0.0997038                 0.0802427\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_64    0.283291  0.080254   0.213922  0.104213                  0.080254\n",
      "StackedEnsemble_AllModels_3_AutoML_2_20240416_130202     0.283406  0.0803192  0.215598  0.101197                  0.0803192\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_394            0.283413  0.0803228  0.216424  0.0994658                 0.0803228\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_808            0.283477  0.0803594  0.215104  0.0997631                 0.0803594\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_45    0.283597  0.0804271  0.210732  0.104363                  0.0804271\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_586            0.283641  0.0804524  0.215944  0.0995797                 0.0804524\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_352            0.28381   0.0805481  0.21752   0.100587                  0.0805481\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_318            0.283828  0.0805584  0.217845  0.099164                  0.0805584\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_546            0.283844  0.0805676  0.216214  0.100385                  0.0805676\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_490            0.28392   0.0806103  0.216123  0.100584                  0.0806103\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_446            0.284002  0.0806572  0.220048  0.099826                  0.0806572\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_1     0.284057  0.0806883  0.224223  0.102779                  0.0806883\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_513            0.28412   0.080724   0.215646  0.100206                  0.080724\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_209            0.284172  0.0807539  0.221046  0.0997867                 0.0807539\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_321            0.284219  0.0807803  0.223414  0.0987682                 0.0807803\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_690            0.284233  0.0807886  0.218963  0.0999114                 0.0807886\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_19    0.284326  0.0808413  0.215495  0.106354                  0.0808413\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_529            0.284339  0.0808489  0.226153  0.0996247                 0.0808489\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_7              0.28434   0.0808493  0.219437  0.0989666                 0.0808493\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_255            0.284506  0.0809434  0.225013  0.100753                  0.0809434\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_647            0.284536  0.0809609  0.222278  0.10044                   0.0809609\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_166            0.284541  0.0809638  0.221619  0.0994128                 0.0809638\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_780            0.28467   0.0810372  0.217029  0.100307                  0.0810372\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_29    0.28474   0.0810767  0.222259  0.104912                  0.0810767\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_222            0.284823  0.0811239  0.213876  0.100543                  0.0811239\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_39    0.284878  0.0811555  0.215434  0.100304                  0.0811555\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_496            0.284902  0.0811692  0.215642  0.101253                  0.0811692\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_695            0.284954  0.0811989  0.219951  0.100449                  0.0811989\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_662            0.284978  0.0812122  0.213022  0.101071                  0.0812122\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_805            0.284982  0.0812149  0.214451  0.100271                  0.0812149\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_680            0.285059  0.0812589  0.216743  0.101208                  0.0812589\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_12    0.285144  0.0813072  0.228362  0.100147                  0.0813072\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_180            0.285165  0.0813191  0.219151  0.101474                  0.0813191\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_247            0.285279  0.0813842  0.217939  0.100494                  0.0813842\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_370            0.285367  0.0814343  0.223564  0.100215                  0.0814343\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_412            0.285443  0.0814776  0.219546  0.100488                  0.0814776\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_189            0.285446  0.0814794  0.221663  0.100475                  0.0814794\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_480            0.28547   0.0814931  0.219064  0.0998788                 0.0814931\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_575            0.285517  0.0815198  0.223928  0.0999606                 0.0815198\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_107   0.285616  0.0815766  0.214984  0.106113                  0.0815766\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_640            0.28564   0.08159    0.218597  0.100824                  0.08159\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_705            0.285771  0.0816648  0.215224  0.101099                  0.0816648\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_87    0.285827  0.0816973  0.229273  0.101199                  0.0816973\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_194            0.285924  0.0817524  0.221022  0.10088                   0.0817524\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_410            0.285992  0.0817912  0.218865  0.1011                    0.0817912\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_357            0.285999  0.0817954  0.217664  0.0996916                 0.0817954\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_792            0.286141  0.0818764  0.227383  0.0989347                 0.0818764\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_356            0.286159  0.0818872  0.217293  0.102064                  0.0818872\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_95    0.286271  0.081951   0.222273  0.105212                  0.081951\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_43    0.286329  0.0819843  0.216471  0.103443                  0.0819843\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_554            0.286377  0.0820115  0.21607   0.101996                  0.0820115\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_254            0.286393  0.082021   0.219053  0.101499                  0.082021\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_65    0.286414  0.0820331  0.220147  0.104514                  0.0820331\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_344            0.286494  0.0820789  0.21642   0.102269                  0.0820789\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_160            0.286495  0.0820796  0.2208    0.0995449                 0.0820796\n",
      "GBM_4_AutoML_2_20240416_130202                           0.286571  0.082123   0.215524  0.100491                  0.082123\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_77             0.286609  0.0821449  0.211444  0.101163                  0.0821449\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_274            0.286621  0.0821515  0.224203  0.100812                  0.0821515\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_157            0.286661  0.0821744  0.221152  0.100535                  0.0821744\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_402            0.2867    0.0821969  0.214023  0.101662                  0.0821969\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_749            0.286717  0.0822067  0.216045  0.0995628                 0.0822067\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_368            0.286818  0.0822647  0.222723  0.101125                  0.0822647\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_19    0.286841  0.0822775  0.216515  0.106325                  0.0822775\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_470            0.286854  0.082285   0.215342  0.100515                  0.082285\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_161            0.286879  0.0822996  0.218749  0.101824                  0.0822996\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_33             0.286964  0.0823482  0.216435  0.100873                  0.0823482\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_21             0.286967  0.08235    0.222043  0.102048                  0.08235\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_543            0.287041  0.0823928  0.218364  0.100944                  0.0823928\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_73             0.28717   0.0824668  0.219517  0.0999115                 0.0824668\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_708            0.287257  0.0825166  0.224668  0.101092                  0.0825166\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_536            0.287293  0.082537   0.213555  0.102187                  0.082537\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_663            0.287584  0.0827048  0.221856  0.102192                  0.0827048\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_744            0.28776   0.0828061  0.227635  0.101113                  0.0828061\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_489            0.287809  0.0828342  0.221722  0.102706                  0.0828342\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_4     0.287912  0.0828934  0.222299  0.104534                  0.0828934\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_810            0.287929  0.0829033  0.217072  0.100883                  0.0829033\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_34    0.287942  0.0829103  0.220563  0.104252                  0.0829103\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_364            0.287952  0.0829165  0.22399   0.103009                  0.0829165\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_228            0.288024  0.0829579  0.223134  0.101337                  0.0829579\n",
      "StackedEnsemble_Best1000_1_AutoML_2_20240416_130202      0.288025  0.0829584  0.218843  0.103062                  0.0829584\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_482            0.288045  0.08297    0.224022  0.101622                  0.08297\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_661            0.288049  0.0829725  0.222189  0.0999137                 0.0829725\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_3     0.288075  0.0829873  0.219047  0.102647                  0.0829873\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_361            0.288084  0.0829923  0.220587  0.102061                  0.0829923\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_60    0.288159  0.0830356  0.210946  0.104148                  0.0830356\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_566            0.288176  0.0830454  0.220144  0.100641                  0.0830454\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_230            0.288191  0.0830541  0.216947  0.10199                   0.0830541\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_612            0.288231  0.0830772  0.216033  0.100964                  0.0830772\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_73    0.288266  0.0830975  0.231666  0.103474                  0.0830975\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_585            0.288306  0.0831203  0.21994   0.101316                  0.0831203\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_563            0.288363  0.0831533  0.217381  0.102528                  0.0831533\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_292            0.288455  0.0832062  0.221599  0.101616                  0.0832062\n",
      "GBM_2_AutoML_2_20240416_130202                           0.288459  0.0832084  0.226704  0.101999                  0.0832084\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_270            0.288488  0.0832252  0.220737  0.101445                  0.0832252\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_598            0.288495  0.0832292  0.224086  0.101134                  0.0832292\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_358            0.288744  0.0833734  0.221199  0.100812                  0.0833734\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_151            0.288747  0.083375   0.223456  0.101684                  0.083375\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_492            0.288768  0.083387   0.212925  0.103267                  0.083387\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_646            0.288794  0.0834019  0.218776  0.101895                  0.0834019\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_337            0.288798  0.0834041  0.222705  0.10151                   0.0834041\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_716            0.288816  0.0834149  0.210976  0.102013                  0.0834149\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_16    0.288907  0.0834673  0.229891  0.105372                  0.0834673\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_55             0.288912  0.08347    0.219592  0.102211                  0.08347\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_788            0.288928  0.0834794  0.223205  0.10146                   0.0834794\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_101   0.288934  0.0834831  0.220743  0.103678                  0.0834831\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_502            0.288985  0.0835121  0.223646  0.101147                  0.0835121\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_4     0.289014  0.0835294  0.225071  0.105889                  0.0835294\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_679            0.289024  0.0835348  0.22082   0.101699                  0.0835348\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_698            0.28909   0.0835731  0.2252    0.101185                  0.0835731\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_618            0.289095  0.0835761  0.220118  0.102605                  0.0835761\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_353            0.289195  0.0836336  0.217706  0.101051                  0.0836336\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_567            0.289239  0.0836593  0.220861  0.101408                  0.0836593\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_676            0.289258  0.08367    0.21977   0.101133                  0.08367\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_491            0.289261  0.0836721  0.22218   0.10159                   0.0836721\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_722            0.289281  0.0836834  0.221834  0.100714                  0.0836834\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_706            0.289286  0.0836865  0.218805  0.101484                  0.0836865\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_204            0.289295  0.0836916  0.222957  0.102461                  0.0836916\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_46             0.289348  0.0837225  0.226782  0.100123                  0.0837225\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_377            0.289479  0.0837981  0.216179  0.101224                  0.0837981\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_42             0.289525  0.0838248  0.223653  0.100843                  0.0838248\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_392            0.289618  0.0838783  0.223746  0.101793                  0.0838783\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_174            0.289629  0.083885   0.223075  0.101251                  0.083885\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_298            0.289742  0.0839506  0.221845  0.102953                  0.0839506\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_596            0.289754  0.0839573  0.223865  0.101833                  0.0839573\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_214            0.289758  0.0839598  0.222949  0.101938                  0.0839598\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_549            0.289791  0.0839786  0.223261  0.101105                  0.0839786\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_235            0.289822  0.0839965  0.215625  0.101352                  0.0839965\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_711            0.289861  0.0840192  0.222794  0.101001                  0.0840192\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_769            0.29      0.0840998  0.222299  0.101227                  0.0840998\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_59             0.29      0.0840999  0.225593  0.101616                  0.0840999\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_395            0.290042  0.0841242  0.224002  0.101296                  0.0841242\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_442            0.290095  0.0841554  0.225772  0.101536                  0.0841554\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_3     0.290122  0.0841705  0.228256  0.105376                  0.0841705\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_514            0.290141  0.0841815  0.220343  0.103022                  0.0841815\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_294            0.29017   0.0841985  0.229507  0.100944                  0.0841985\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_687            0.290195  0.0842133  0.226968  0.101256                  0.0842133\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_7     0.290203  0.084218   0.222635  0.109053                  0.084218\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_407            0.290294  0.0842705  0.223801  0.101939                  0.0842705\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_761            0.290298  0.0842727  0.225954  0.101486                  0.0842727\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_280            0.290316  0.0842833  0.222293  0.101282                  0.0842833\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_163            0.290409  0.0843372  0.222179  0.102954                  0.0843372\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_459            0.290443  0.0843571  0.22181   0.101262                  0.0843571\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_246            0.290454  0.0843638  0.221815  0.101079                  0.0843638\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_237            0.290455  0.0843639  0.227926  0.103164                  0.0843639\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_724            0.290499  0.0843897  0.221052  0.10127                   0.0843897\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_42    0.290503  0.0843919  0.223159  0.110827                  0.0843919\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_604            0.290524  0.0844042  0.226056  0.101748                  0.0844042\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_403            0.290588  0.0844414  0.2261    0.101934                  0.0844414\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_29    0.290596  0.0844458  0.226942  0.106818                  0.0844458\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_562            0.290607  0.0844526  0.225924  0.100652                  0.0844526\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_68             0.290656  0.084481   0.223362  0.102058                  0.084481\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_800            0.290724  0.0845202  0.216606  0.102118                  0.0845202\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_404            0.290739  0.084529   0.216837  0.103438                  0.084529\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_308            0.290755  0.0845387  0.220845  0.103519                  0.0845387\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_10    0.290781  0.0845537  0.22672   0.107842                  0.0845537\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_71    0.29079   0.0845587  0.220456  0.108902                  0.0845587\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_597            0.290824  0.0845785  0.22452   0.101476                  0.0845785\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_9              0.290886  0.0846147  0.221684  0.102526                  0.0846147\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_775            0.290947  0.0846502  0.224115  0.101811                  0.0846502\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_378            0.290994  0.0846778  0.22259   0.103                     0.0846778\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_738            0.290995  0.0846779  0.215236  0.102048                  0.0846779\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_302            0.291049  0.0847094  0.225339  0.102279                  0.0847094\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_607            0.291059  0.0847153  0.222646  0.101663                  0.0847153\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_304            0.291067  0.0847198  0.226436  0.102872                  0.0847198\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_450            0.291106  0.0847428  0.220005  0.101811                  0.0847428\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_441            0.291324  0.0848699  0.223808  0.102428                  0.0848699\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_430            0.291396  0.0849114  0.224825  0.103013                  0.0849114\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_154            0.291591  0.0850255  0.220541  0.10144                   0.0850255\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_571            0.291631  0.0850487  0.221833  0.101627                  0.0850487\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_238            0.291709  0.085094   0.211345  0.103859                  0.085094\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_53    0.291741  0.085113   0.219498  0.102961                  0.085113\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_623            0.291781  0.0851362  0.226709  0.103735                  0.0851362\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_339            0.291805  0.0851499  0.220781  0.101532                  0.0851499\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_379            0.291927  0.0852213  0.221624  0.101708                  0.0852213\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_447            0.291968  0.0852453  0.225771  0.101657                  0.0852453\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_217            0.291987  0.0852565  0.223182  0.100251                  0.0852565\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_112   0.29209   0.0853168  0.218124  0.103595                  0.0853168\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_580            0.292094  0.0853187  0.220845  0.102402                  0.0853187\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_538            0.292142  0.0853472  0.221834  0.102098                  0.0853472\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_750            0.292212  0.0853878  0.225065  0.102472                  0.0853878\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_476            0.292276  0.0854251  0.224995  0.102219                  0.0854251\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_709            0.292306  0.0854428  0.228325  0.102645                  0.0854428\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_654            0.292381  0.0854868  0.22333   0.102421                  0.0854868\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_703            0.292397  0.0854959  0.221831  0.102517                  0.0854959\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_262   0.292417  0.0855079  0.232386  0.104014                  0.0855079\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_599            0.29249   0.0855502  0.223861  0.102536                  0.0855502\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_27    0.292503  0.085558   0.225294  0.107916                  0.085558\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_641            0.292527  0.0855721  0.223856  0.102003                  0.0855721\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_811            0.292531  0.0855741  0.232722  0.102511                  0.0855741\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_668            0.292582  0.085604   0.227858  0.10211                   0.085604\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_648            0.292583  0.0856047  0.224494  0.102312                  0.0856047\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_93    0.29263   0.0856326  0.220118  0.107685                  0.0856326\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_208            0.292653  0.085646   0.225717  0.102446                  0.085646\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_331            0.292661  0.0856505  0.219497  0.103543                  0.0856505\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_175            0.292768  0.0857131  0.22053   0.102853                  0.0857131\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_242            0.292825  0.0857468  0.225748  0.102497                  0.0857468\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_574            0.292884  0.0857809  0.222034  0.101903                  0.0857809\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_719            0.292908  0.0857952  0.21973   0.102466                  0.0857952\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_276            0.292923  0.0858042  0.22265   0.102995                  0.0858042\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_49    0.292993  0.0858447  0.228741  0.10566                   0.0858447\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_7     0.293016  0.0858581  0.231509  0.10663                   0.0858581\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_484            0.293037  0.0858709  0.225818  0.103053                  0.0858709\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_520            0.293044  0.0858749  0.227473  0.102752                  0.0858749\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_203            0.293063  0.085886   0.221483  0.102488                  0.085886\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_62    0.293081  0.0858965  0.234845  0.106704                  0.0858965\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_220            0.293109  0.0859131  0.232233  0.102683                  0.0859131\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_179            0.293211  0.0859724  0.221571  0.102129                  0.0859724\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_688            0.293217  0.0859762  0.224467  0.102886                  0.0859762\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_41             0.293224  0.0859803  0.227096  0.102419                  0.0859803\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_24             0.293262  0.0860024  0.227092  0.103107                  0.0860024\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_534            0.293276  0.0860106  0.223756  0.102115                  0.0860106\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_8     0.293294  0.0860216  0.226217  0.110102                  0.0860216\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_485            0.293306  0.0860283  0.219974  0.101741                  0.0860283\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_256            0.293365  0.0860631  0.223811  0.102358                  0.0860631\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_248   0.293402  0.0860847  0.235385  0.106465                  0.0860847\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_620            0.293446  0.0861104  0.227597  0.103358                  0.0861104\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_799            0.29346   0.0861188  0.226055  0.103574                  0.0861188\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_28             0.293487  0.0861345  0.222699  0.103496                  0.0861345\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_581            0.293518  0.0861527  0.231102  0.103315                  0.0861527\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_279            0.293558  0.0861764  0.22066   0.103565                  0.0861764\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_35             0.29356   0.0861774  0.223718  0.103244                  0.0861774\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_287            0.293566  0.0861807  0.223979  0.103638                  0.0861807\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_793            0.293622  0.0862137  0.222406  0.102353                  0.0862137\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_348            0.293624  0.0862153  0.229962  0.102747                  0.0862153\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_30    0.293661  0.0862367  0.229849  0.11055                   0.0862367\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_211            0.293668  0.0862411  0.223578  0.102773                  0.0862411\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_770            0.29368   0.0862478  0.219738  0.104608                  0.0862478\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_740            0.293691  0.0862541  0.226149  0.103288                  0.0862541\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_207            0.293697  0.0862578  0.225628  0.101931                  0.0862578\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_109   0.293737  0.0862816  0.227482  0.102635                  0.0862816\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_624            0.293767  0.0862988  0.227809  0.10413                   0.0862988\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_366            0.293872  0.0863605  0.225951  0.103067                  0.0863605\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_245            0.293879  0.0863647  0.221171  0.102462                  0.0863647\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_713            0.293882  0.0863666  0.228353  0.103137                  0.0863666\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_43             0.293914  0.0863853  0.222903  0.102714                  0.0863853\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_621            0.293941  0.0864015  0.221769  0.103679                  0.0864015\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_268            0.293996  0.0864336  0.225751  0.10237                   0.0864336\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_686            0.294037  0.086458   0.224326  0.102545                  0.086458\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_98    0.294052  0.0864664  0.217026  0.104614                  0.0864664\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_22             0.294058  0.0864702  0.222492  0.103391                  0.0864702\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_657            0.294068  0.0864762  0.223293  0.103372                  0.0864762\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_153            0.294108  0.0864996  0.225298  0.102067                  0.0864996\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_253            0.294132  0.0865137  0.221436  0.102878                  0.0865137\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_630            0.294137  0.0865166  0.225913  0.10309                   0.0865166\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_699            0.294206  0.0865572  0.222386  0.103339                  0.0865572\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_465            0.294218  0.0865643  0.222396  0.103755                  0.0865643\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_635            0.294219  0.0865648  0.226281  0.102466                  0.0865648\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_9     0.294238  0.0865757  0.223797  0.103669                  0.0865757\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_82    0.294248  0.0865821  0.223294  0.102287                  0.0865821\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_162            0.29431   0.0866186  0.220814  0.103778                  0.0866186\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_568            0.294402  0.0866726  0.227356  0.102595                  0.0866726\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_455            0.294501  0.086731   0.224905  0.103151                  0.086731\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_241            0.294551  0.0867601  0.227332  0.102778                  0.0867601\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_435            0.294563  0.0867672  0.22677   0.102557                  0.0867672\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_143            0.294571  0.0867721  0.222868  0.10335                   0.0867721\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_37    0.29465   0.0868187  0.230838  0.100705                  0.0868187\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_1     0.29469   0.0868425  0.226664  0.109752                  0.0868425\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_794            0.294712  0.086855   0.222344  0.102515                  0.086855\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_75             0.294753  0.0868791  0.223064  0.103178                  0.0868791\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_236            0.294792  0.0869023  0.226254  0.103169                  0.0869023\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_472            0.294855  0.0869392  0.227829  0.103056                  0.0869392\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_481            0.294916  0.0869757  0.225787  0.102602                  0.0869757\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_347            0.294932  0.0869847  0.229425  0.102087                  0.0869847\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_367            0.294948  0.086994   0.223522  0.103718                  0.086994\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_198            0.295134  0.0871038  0.225486  0.103695                  0.0871038\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_519            0.295146  0.087111   0.226384  0.103168                  0.087111\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_531            0.295188  0.0871362  0.224013  0.102829                  0.0871362\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_440            0.295203  0.0871447  0.231061  0.102988                  0.0871447\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_333            0.295289  0.0871956  0.226903  0.1028                    0.0871956\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_739            0.295299  0.0872015  0.226567  0.10342                   0.0872015\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_626            0.295313  0.0872095  0.221142  0.103809                  0.0872095\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_26             0.295315  0.0872111  0.225047  0.104337                  0.0872111\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_219            0.295334  0.087222   0.222202  0.102718                  0.087222\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_681            0.295461  0.0872972  0.221718  0.103783                  0.0872972\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_445            0.295492  0.0873153  0.221129  0.104161                  0.0873153\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_417            0.295505  0.0873234  0.223644  0.102786                  0.0873234\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_710            0.29555   0.0873499  0.226203  0.103288                  0.0873499\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_12             0.295556  0.0873533  0.225708  0.103371                  0.0873533\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_56             0.295583  0.0873695  0.22533   0.10325                   0.0873695\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_8     0.295587  0.0873716  0.225687  0.109563                  0.0873716\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_272            0.295608  0.0873839  0.22594   0.103402                  0.0873839\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_5              0.29566   0.087415   0.22326   0.103504                  0.087415\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_273            0.295681  0.0874272  0.231619  0.10396                   0.0874272\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_461            0.295696  0.0874363  0.225502  0.103307                  0.0874363\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_33    0.295727  0.0874545  0.240201  0.106582                  0.0874545\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_504            0.295815  0.0875064  0.223273  0.102971                  0.0875064\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_677            0.295825  0.0875123  0.226007  0.104491                  0.0875123\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_90    0.295842  0.0875228  0.219476  0.106279                  0.0875228\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_807            0.295885  0.0875476  0.228552  0.103414                  0.0875476\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_300            0.295988  0.0876088  0.225284  0.102862                  0.0876088\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_20    0.29612   0.0876869  0.222792  0.106071                  0.0876869\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_391            0.296122  0.0876883  0.22964   0.104003                  0.0876883\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_473            0.296131  0.0876935  0.226111  0.10338                   0.0876935\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_487            0.296142  0.0877     0.227614  0.103462                  0.0877\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_803            0.296226  0.0877501  0.228838  0.104298                  0.0877501\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_350            0.296291  0.0877881  0.223711  0.103228                  0.0877881\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_190            0.296304  0.0877963  0.229734  0.104522                  0.0877963\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_94    0.296383  0.0878429  0.227874  0.113236                  0.0878429\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_225            0.296408  0.0878574  0.221767  0.103225                  0.0878574\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_44             0.296418  0.0878639  0.231389  0.104136                  0.0878639\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_464            0.29646   0.0878884  0.225537  0.103406                  0.0878884\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_360            0.296464  0.0878911  0.226891  0.102976                  0.0878911\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_70             0.296494  0.0879088  0.22925   0.103276                  0.0879088\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_503            0.296501  0.0879128  0.223705  0.103621                  0.0879128\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_684            0.29652   0.0879243  0.227067  0.103857                  0.0879243\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_390            0.296572  0.0879552  0.226608  0.103105                  0.0879552\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_741            0.296574  0.0879561  0.230437  0.103678                  0.0879561\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_182            0.296631  0.0879901  0.224787  0.103221                  0.0879901\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_55    0.296657  0.0880057  0.217427  0.105058                  0.0880057\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_288            0.29666   0.0880069  0.220218  0.104627                  0.0880069\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_30    0.296669  0.0880125  0.232936  0.110107                  0.0880125\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_791            0.296692  0.088026   0.227422  0.104048                  0.088026\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_141            0.296712  0.0880381  0.227642  0.103693                  0.0880381\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_69             0.296728  0.0880476  0.225332  0.103544                  0.0880476\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_449            0.29674   0.0880546  0.227216  0.102644                  0.0880546\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_583            0.296768  0.0880712  0.220351  0.103629                  0.0880712\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_373            0.296853  0.0881216  0.230184  0.103924                  0.0881216\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_572            0.296982  0.0881982  0.233524  0.104414                  0.0881982\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_314            0.297006  0.0882123  0.230799  0.103105                  0.0882123\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_516            0.297034  0.0882289  0.22985   0.103488                  0.0882289\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_359            0.297083  0.0882583  0.222148  0.103339                  0.0882583\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_8              0.297102  0.0882694  0.227131  0.103353                  0.0882694\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_307            0.297178  0.088315   0.234361  0.10369                   0.088315\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_475            0.297196  0.0883255  0.226584  0.102987                  0.0883255\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_227            0.297231  0.0883462  0.225022  0.10484                   0.0883462\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_712            0.297256  0.0883611  0.225354  0.103969                  0.0883611\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_448            0.297288  0.0883801  0.225092  0.103784                  0.0883801\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_165            0.297289  0.0883809  0.227747  0.103665                  0.0883809\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_4     0.297294  0.088384   0.224066  0.110313                  0.088384\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_425            0.297349  0.0884163  0.228783  0.102734                  0.0884163\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_798            0.297389  0.0884404  0.229006  0.104195                  0.0884404\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_547            0.297413  0.0884544  0.219659  0.104315                  0.0884544\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_159            0.297427  0.0884626  0.225491  0.103798                  0.0884626\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_565            0.297444  0.0884727  0.227081  0.103994                  0.0884727\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_10             0.297451  0.0884773  0.225413  0.10433                   0.0884773\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_423            0.297622  0.0885788  0.227797  0.103729                  0.0885788\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_509            0.297652  0.0885968  0.233764  0.104258                  0.0885968\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_772            0.297732  0.0886443  0.228179  0.103656                  0.0886443\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_573            0.29775   0.0886552  0.226862  0.103867                  0.0886552\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_594            0.297764  0.0886634  0.225922  0.103689                  0.0886634\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_293            0.297767  0.0886653  0.226638  0.103781                  0.0886653\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_213            0.297836  0.088706   0.228472  0.104581                  0.088706\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_334            0.297923  0.0887581  0.225292  0.10505                   0.0887581\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_40             0.298031  0.0888224  0.22259   0.105937                  0.0888224\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_401            0.298048  0.0888324  0.229394  0.104588                  0.0888324\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_589            0.298135  0.0888847  0.229918  0.105091                  0.0888847\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_383            0.298186  0.0889149  0.232843  0.103928                  0.0889149\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_260            0.298418  0.0890535  0.227876  0.104381                  0.0890535\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_332            0.298451  0.0890732  0.220798  0.103277                  0.0890732\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_15    0.298568  0.0891426  0.228967  0.108525                  0.0891426\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_787            0.298616  0.0891717  0.231771  0.104474                  0.0891717\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_522            0.298631  0.0891806  0.228875  0.104437                  0.0891806\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_85    0.298654  0.0891941  0.219074  0.0996422                 0.0891941\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_362            0.298717  0.0892319  0.228939  0.106221                  0.0892319\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_758            0.298795  0.0892786  0.232916  0.104329                  0.0892786\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_50    0.298809  0.0892869  0.226356  0.104585                  0.0892869\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_670            0.298865  0.0893203  0.229882  0.10527                   0.0893203\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_608            0.298888  0.0893338  0.230768  0.104054                  0.0893338\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_2              0.298893  0.0893371  0.22102   0.104872                  0.0893371\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_262            0.298954  0.0893732  0.22903   0.103359                  0.0893732\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_721            0.299141  0.0894851  0.230197  0.103523                  0.0894851\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_767            0.299183  0.0895102  0.228771  0.103469                  0.0895102\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_28    0.299225  0.0895357  0.23775   0.108488                  0.0895357\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_14    0.299304  0.0895831  0.236635  0.10867                   0.0895831\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_149            0.299308  0.0895852  0.225793  0.103665                  0.0895852\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_653            0.299471  0.0896831  0.23558   0.104942                  0.0896831\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_505            0.299483  0.0896903  0.230098  0.104412                  0.0896903\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_340            0.299497  0.0896986  0.23394   0.106026                  0.0896986\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_642            0.299519  0.0897118  0.229192  0.104425                  0.0897118\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_616            0.299546  0.0897278  0.230809  0.104304                  0.0897278\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_463            0.299553  0.0897321  0.232709  0.105835                  0.0897321\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_759            0.299565  0.0897393  0.232043  0.104129                  0.0897393\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_494            0.299626  0.0897759  0.227576  0.104911                  0.0897759\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_23             0.299628  0.0897768  0.228003  0.10473                   0.0897768\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_753            0.299666  0.0897999  0.227213  0.104803                  0.0897999\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_197            0.29981   0.0898862  0.22725   0.105031                  0.0898862\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_601            0.299816  0.0898898  0.238329  0.106537                  0.0898898\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_15    0.299832  0.0898993  0.234691  0.110293                  0.0898993\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_17             0.299835  0.0899012  0.231421  0.105096                  0.0899012\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_299            0.299874  0.0899243  0.222376  0.104109                  0.0899243\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_50             0.299898  0.0899386  0.227302  0.104621                  0.0899386\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_424            0.300056  0.0900334  0.227081  0.103972                  0.0900334\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_310            0.300175  0.090105   0.228495  0.103427                  0.090105\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_150            0.300175  0.0901051  0.229005  0.107756                  0.0901051\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_234            0.300186  0.0901116  0.228431  0.105164                  0.0901116\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_551            0.300202  0.0901214  0.23833   0.105246                  0.0901214\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_453            0.300219  0.0901314  0.22556   0.105709                  0.0901314\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_488            0.300225  0.0901351  0.227701  0.103677                  0.0901351\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_606            0.300235  0.0901409  0.232634  0.10703                   0.0901409\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_658            0.300333  0.0902002  0.226928  0.105077                  0.0902002\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_53             0.300395  0.0902372  0.224508  0.104204                  0.0902372\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_731            0.300402  0.0902414  0.226719  0.105724                  0.0902414\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_559            0.300424  0.0902548  0.231517  0.104938                  0.0902548\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_34             0.300674  0.0904049  0.229137  0.104385                  0.0904049\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_34    0.300718  0.0904312  0.230911  0.10987                   0.0904312\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_335            0.300729  0.0904382  0.225424  0.105332                  0.0904382\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_264            0.30076   0.0904564  0.227364  0.104504                  0.0904564\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_763            0.300765  0.0904594  0.228493  0.104691                  0.0904594\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_501            0.300785  0.0904716  0.232541  0.105502                  0.0904716\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_570            0.300814  0.090489   0.233686  0.106516                  0.090489\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_622            0.300838  0.0905035  0.226955  0.104928                  0.0905035\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_483            0.300846  0.0905081  0.23322   0.105494                  0.0905081\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_745            0.30102   0.090613   0.228936  0.104542                  0.090613\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_193            0.301048  0.0906299  0.232611  0.106072                  0.0906299\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_295            0.301063  0.0906388  0.234287  0.105826                  0.0906388\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_762            0.30107   0.0906431  0.229856  0.104442                  0.0906431\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_66             0.301192  0.0907169  0.230813  0.10535                   0.0907169\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_611            0.301283  0.0907715  0.230229  0.10467                   0.0907715\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_63             0.301304  0.0907841  0.223478  0.1048                    0.0907841\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_42    0.301437  0.0908644  0.235952  0.106546                  0.0908644\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_497            0.301451  0.090873   0.231476  0.104359                  0.090873\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_7     0.301512  0.0909095  0.233115  0.112046                  0.0909095\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_346            0.301515  0.0909111  0.230832  0.10662                   0.0909111\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_782            0.301632  0.0909817  0.234534  0.105325                  0.0909817\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_399            0.301847  0.0911118  0.228953  0.106264                  0.0911118\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_265            0.301935  0.0911649  0.235687  0.10597                   0.0911649\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_152            0.301999  0.0912032  0.232882  0.105716                  0.0912032\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_778            0.302027  0.0912202  0.227427  0.10485                   0.0912202\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_521            0.302132  0.0912837  0.226703  0.105332                  0.0912837\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_382            0.302333  0.0914053  0.230511  0.106155                  0.0914053\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_47    0.302369  0.091427   0.240774  0.10561                   0.091427\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_678            0.30256   0.0915428  0.23243   0.106858                  0.0915428\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_242   0.302666  0.0916069  0.228872  0.106647                  0.0916069\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_474            0.302693  0.0916229  0.232352  0.107668                  0.0916229\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_696            0.302831  0.0917068  0.230799  0.106503                  0.0917068\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_605            0.302879  0.0917358  0.230447  0.107325                  0.0917358\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_320            0.302924  0.091763   0.229343  0.107217                  0.091763\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_285            0.303002  0.0918102  0.229172  0.106829                  0.0918102\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_70    0.303057  0.0918435  0.226021  0.114343                  0.0918435\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_422            0.303159  0.0919052  0.232465  0.106613                  0.0919052\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_539            0.303222  0.0919437  0.232253  0.106414                  0.0919437\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_419            0.303256  0.0919644  0.228967  0.105217                  0.0919644\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_530            0.303275  0.0919755  0.234759  0.106177                  0.0919755\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_564            0.303309  0.0919963  0.239552  0.104503                  0.0919963\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_590            0.303343  0.0920172  0.227169  0.10507                   0.0920172\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_675            0.303772  0.0922775  0.230169  0.105524                  0.0922775\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_466            0.303793  0.09229    0.233052  0.106572                  0.09229\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_186            0.303795  0.0922914  0.235283  0.106881                  0.0922914\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_452            0.303844  0.0923213  0.23509   0.10566                   0.0923213\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_413            0.303879  0.0923425  0.232139  0.106858                  0.0923425\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_13             0.303929  0.0923728  0.244738  0.107594                  0.0923728\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_3     0.304237  0.09256    0.236464  0.108643                  0.09256\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_156            0.304377  0.0926453  0.235097  0.106797                  0.0926453\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_467            0.304385  0.0926503  0.234213  0.107298                  0.0926503\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_263            0.304422  0.0926725  0.233906  0.105927                  0.0926725\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_545            0.304423  0.0926731  0.228179  0.105894                  0.0926731\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_625            0.304439  0.0926833  0.23452   0.107869                  0.0926833\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_418            0.304645  0.0928087  0.230091  0.106664                  0.0928087\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_754            0.305037  0.0930476  0.231905  0.107428                  0.0930476\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_192            0.305073  0.0930698  0.239131  0.109205                  0.0930698\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_790            0.305288  0.093201   0.23072   0.10556                   0.093201\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_20    0.305611  0.0933981  0.236688  0.111299                  0.0933981\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_27    0.305767  0.0934934  0.245484  0.108054                  0.0934934\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_47             0.305784  0.0935041  0.235907  0.108419                  0.0935041\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_540            0.305911  0.0935815  0.224701  0.107614                  0.0935815\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_671            0.305912  0.0935822  0.234871  0.107122                  0.0935822\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_643            0.305914  0.0935831  0.23405   0.105727                  0.0935831\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_495            0.305999  0.0936351  0.235107  0.106595                  0.0936351\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_652            0.3061    0.0936974  0.237212  0.107078                  0.0936974\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_493            0.3061    0.0936974  0.237212  0.107078                  0.0936974\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_322            0.306198  0.0937573  0.234117  0.106577                  0.0937573\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_632            0.306233  0.0937788  0.239207  0.108273                  0.0937788\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_526            0.306459  0.0939172  0.229357  0.10636                   0.0939172\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_14    0.306496  0.0939399  0.242849  0.109525                  0.0939399\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_243   0.306502  0.0939437  0.239112  0.114162                  0.0939437\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_257   0.306553  0.0939747  0.237865  0.108969                  0.0939747\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_261   0.306765  0.0941048  0.234842  0.106764                  0.0941048\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_91    0.306894  0.0941841  0.238528  0.103194                  0.0941841\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_718            0.306986  0.0942403  0.233281  0.106951                  0.0942403\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_479            0.307344  0.0944602  0.23709   0.108117                  0.0944602\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_223            0.307556  0.094591   0.23153   0.107129                  0.094591\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_306            0.307757  0.0947144  0.238926  0.108317                  0.0947144\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_351            0.308244  0.0950142  0.235446  0.108583                  0.0950142\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_576            0.308279  0.0950361  0.230769  0.106368                  0.0950361\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_797            0.308304  0.0950512  0.238214  0.11048                   0.0950512\n",
      "GBM_3_AutoML_2_20240416_130202                           0.308483  0.0951618  0.229897  0.108371                  0.0951618\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_13    0.308559  0.0952086  0.237571  0.111921                  0.0952086\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_9     0.308656  0.0952688  0.246137  0.110569                  0.0952688\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_170            0.308751  0.0953274  0.238893  0.108014                  0.0953274\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_267            0.308807  0.0953616  0.233429  0.10954                   0.0953616\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_518            0.309142  0.095569   0.237992  0.109566                  0.095569\n",
      "GBM_5_AutoML_2_20240416_130202                           0.30921   0.0956107  0.236168  0.107729                  0.0956107\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_755            0.309386  0.0957196  0.239767  0.108606                  0.0957196\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_614            0.309459  0.0957649  0.240827  0.10735                   0.0957649\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_329            0.309585  0.0958429  0.239195  0.107807                  0.0958429\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_672            0.309639  0.095876   0.23627   0.108014                  0.095876\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_16    0.309669  0.0958952  0.243019  0.112729                  0.0958952\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_325            0.309803  0.0959777  0.234297  0.108562                  0.0959777\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_21    0.30983   0.0959945  0.234841  0.116735                  0.0959945\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_76             0.30988   0.0960255  0.238172  0.108657                  0.0960255\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_443            0.31002   0.0961127  0.240966  0.109148                  0.0961127\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_210            0.310314  0.096295   0.242456  0.10801                   0.096295\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_277            0.310348  0.096316   0.238132  0.108606                  0.096316\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_22    0.3106    0.0964722  0.246435  0.109744                  0.0964722\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_326            0.31064   0.0964969  0.237897  0.107727                  0.0964969\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_96    0.310913  0.0966669  0.238821  0.1135                    0.0966669\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_388            0.310983  0.0967101  0.245212  0.111155                  0.0967101\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_72    0.311136  0.0968058  0.239267  0.11079                   0.0968058\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_37    0.311172  0.0968281  0.24234   0.113737                  0.0968281\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_592            0.311231  0.0968648  0.242386  0.1096                    0.0968648\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_41    0.311308  0.0969124  0.240358  0.113322                  0.0969124\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_627            0.311334  0.096929   0.236082  0.110079                  0.096929\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_21    0.311387  0.0969619  0.230406  0.11369                   0.0969619\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_768            0.31161   0.0971009  0.244564  0.108686                  0.0971009\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_102   0.311748  0.0971869  0.243604  0.115435                  0.0971869\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_118   0.3118    0.0972194  0.244742  0.115706                  0.0972194\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_23    0.311957  0.0973175  0.231166  0.105069                  0.0973175\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_283            0.312009  0.0973497  0.235623  0.109756                  0.0973497\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_258   0.312109  0.0974119  0.240286  0.114756                  0.0974119\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_46    0.312263  0.0975082  0.238167  0.105942                  0.0975082\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_801            0.312287  0.0975234  0.244155  0.109479                  0.0975234\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_438            0.312287  0.0975234  0.244155  0.109479                  0.0975234\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_51             0.312287  0.0975234  0.244155  0.109479                  0.0975234\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_460            0.312287  0.0975234  0.244155  0.109479                  0.0975234\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_725            0.312287  0.0975234  0.244155  0.109479                  0.0975234\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_691            0.312582  0.0977076  0.230715  0.111356                  0.0977076\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_600            0.31266   0.097756   0.235107  0.110167                  0.097756\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_303            0.312737  0.0978047  0.24316   0.109763                  0.0978047\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_250            0.313097  0.0980296  0.243757  0.109338                  0.0980296\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_311            0.31327   0.0981381  0.238232  0.109305                  0.0981381\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_168            0.313368  0.0981998  0.240919  0.110103                  0.0981998\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_117   0.313409  0.098225   0.23908   0.116204                  0.098225\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_221            0.31356   0.09832    0.247271  0.110798                  0.09832\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_462            0.313944  0.0985608  0.238321  0.109728                  0.0985608\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_158            0.31396   0.0985707  0.244062  0.109521                  0.0985707\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_748            0.314079  0.0986455  0.248958  0.108428                  0.0986455\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_16    0.314668  0.0990156  0.234196  0.115091                  0.0990156\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_587            0.314826  0.0991153  0.238319  0.112108                  0.0991153\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_99    0.315117  0.0992989  0.24724   0.105874                  0.0992989\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_369            0.315149  0.0993187  0.241792  0.111895                  0.0993187\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_764            0.315197  0.099349   0.242428  0.110756                  0.099349\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_17    0.315561  0.0995787  0.241636  0.10894                   0.0995787\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_21    0.315608  0.0996081  0.249659  0.114847                  0.0996081\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_628            0.315875  0.099777   0.243704  0.111291                  0.099777\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_550            0.316032  0.0998765  0.245196  0.111861                  0.0998765\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_354            0.316309  0.100051   0.249605  0.111288                  0.100051\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_232            0.316523  0.100187   0.247451  0.110366                  0.100187\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_45             0.316912  0.100433   0.240425  0.110956                  0.100433\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_674            0.316917  0.100436   0.24236   0.109898                  0.100436\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_22    0.317163  0.100593   0.246473  0.113564                  0.100593\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_420            0.317188  0.100608   0.244912  0.110559                  0.100608\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_26    0.317232  0.100636   0.24757   0.113037                  0.100636\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_56    0.317322  0.100693   0.236482  0.115982                  0.100693\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_58             0.317326  0.100696   0.243209  0.112214                  0.100696\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_629            0.317645  0.100898   0.245596  0.112369                  0.100898\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_363            0.31812   0.1012     0.248872  0.111177                  0.1012\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_809            0.318149  0.101219   0.240513  0.114567                  0.101219\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_760            0.318168  0.101231   0.242355  0.111984                  0.101231\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_83    0.318318  0.101326   0.242305  0.106131                  0.101326\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_415            0.318607  0.10151    0.242172  0.111302                  0.10151\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_510            0.318887  0.101689   0.243514  0.11152                   0.101689\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_10    0.318991  0.101755   0.249011  0.112845                  0.101755\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_664            0.319047  0.101791   0.243667  0.111801                  0.101791\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_660            0.319068  0.101804   0.249431  0.112529                  0.101804\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_6     0.319373  0.101999   0.25341   0.115584                  0.101999\n",
      "XRT_1_AutoML_2_20240416_130202                           0.319429  0.102035   0.241891  0.111893                  0.102035\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_251            0.319529  0.102099   0.236134  0.112459                  0.102099\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_191            0.319629  0.102163   0.248931  0.109509                  0.102163\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_43    0.319901  0.102337   0.229205  0.115544                  0.102337\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_11    0.320064  0.102441   0.251731  0.115323                  0.102441\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_36    0.320144  0.102492   0.247211  0.111133                  0.102492\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_386            0.320381  0.102644   0.242541  0.111702                  0.102644\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_18             0.320442  0.102683   0.250564  0.112221                  0.102683\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_408            0.320847  0.102943   0.240149  0.112862                  0.102943\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_802            0.32089   0.102971   0.241456  0.114214                  0.102971\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_115   0.321132  0.103126   0.236914  0.112602                  0.103126\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_375            0.321135  0.103128   0.239289  0.111745                  0.103128\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_45    0.321207  0.103174   0.261248  0.113077                  0.103174\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_15             0.321858  0.103593   0.242452  0.112216                  0.103593\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_69    0.321951  0.103652   0.254067  0.111983                  0.103652\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_682            0.322106  0.103752   0.243506  0.111984                  0.103752\n",
      "DRF_1_AutoML_2_20240416_130202                           0.32263   0.10409    0.241115  0.112551                  0.10409\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_25    0.323136  0.104417   0.260594  0.12015                   0.104417\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_506            0.323684  0.104772   0.240931  0.115471                  0.104772\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_28    0.323817  0.104857   0.252341  0.115017                  0.104857\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_301            0.324112  0.105048   0.251254  0.114257                  0.105048\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_57    0.324585  0.105355   0.247885  0.118728                  0.105355\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_25    0.325807  0.10615    0.248891  0.116958                  0.10615\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_86    0.326216  0.106417   0.252852  0.115296                  0.106417\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_13    0.326224  0.106422   0.255403  0.120337                  0.106422\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_28    0.326661  0.106708   0.244422  0.114554                  0.106708\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_74             0.327477  0.107241   0.250464  0.117771                  0.107241\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_673            0.328109  0.107655   0.25117   0.115008                  0.107655\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_720            0.328263  0.107757   0.24527   0.114592                  0.107757\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_11    0.328551  0.107946   0.253116  0.118208                  0.107946\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_32    0.328635  0.108001   0.254138  0.118562                  0.108001\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_752            0.329208  0.108378   0.249288  0.116107                  0.108378\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_771            0.329432  0.108525   0.251037  0.115905                  0.108525\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_76    0.329621  0.10865    0.257768  0.122579                  0.10865\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_5     0.329624  0.108652   0.25831   0.117565                  0.108652\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_10    0.329698  0.108701   0.254179  0.119952                  0.108701\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_535            0.329944  0.108863   0.251529  0.116354                  0.108863\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_421            0.330947  0.109526   0.257037  0.116176                  0.109526\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_602            0.331995  0.110221   0.248905  0.115742                  0.110221\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_689            0.332007  0.110229   0.2579    0.115213                  0.110229\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_324            0.33209   0.110284   0.254288  0.115451                  0.110284\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_264   0.333076  0.110939   0.250069  0.11453                   0.110939\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_393            0.333528  0.111241   0.259982  0.115765                  0.111241\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_613            0.333549  0.111255   0.260749  0.116208                  0.111255\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_704            0.333891  0.111483   0.257453  0.116296                  0.111483\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_172            0.334053  0.111592   0.258905  0.115534                  0.111592\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_766            0.334187  0.111681   0.264112  0.116134                  0.111681\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_218            0.334305  0.11176    0.260502  0.11619                   0.11176\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_694            0.334449  0.111856   0.257793  0.115966                  0.111856\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_732            0.334545  0.11192    0.255271  0.116316                  0.11192\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_244            0.334763  0.112066   0.249243  0.117612                  0.112066\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_20             0.334992  0.11222    0.262953  0.115893                  0.11222\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_49             0.33546   0.112534   0.263894  0.116378                  0.112534\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_730            0.335658  0.112666   0.258355  0.115632                  0.112666\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_701            0.335781  0.112749   0.261091  0.116966                  0.112749\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_429            0.335809  0.112768   0.26038   0.116129                  0.112768\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_229            0.335832  0.112783   0.260475  0.11619                   0.112783\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_200            0.33608   0.11295    0.264549  0.116892                  0.11295\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_38             0.336083  0.112952   0.259167  0.116232                  0.112952\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_515            0.336214  0.11304    0.258625  0.116492                  0.11304\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_67             0.336402  0.113166   0.261095  0.117235                  0.113166\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_11             0.336577  0.113284   0.261867  0.117792                  0.113284\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_561            0.336617  0.113311   0.261646  0.116683                  0.113311\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_259            0.336831  0.113455   0.262705  0.116872                  0.113455\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_655            0.336832  0.113456   0.262055  0.116998                  0.113456\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_726            0.336846  0.113465   0.257769  0.115853                  0.113465\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_498            0.337122  0.113651   0.263297  0.117243                  0.113651\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_405            0.337132  0.113658   0.258622  0.117471                  0.113658\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_181            0.337181  0.113691   0.263558  0.116882                  0.113691\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_297            0.337184  0.113693   0.263644  0.117209                  0.113693\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_176            0.33724   0.113731   0.262497  0.116817                  0.113731\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_734            0.337343  0.1138     0.260542  0.117027                  0.1138\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_469            0.337379  0.113824   0.261086  0.11686                   0.113824\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_77    0.337449  0.113872   0.25885   0.120114                  0.113872\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_195            0.337459  0.113878   0.261129  0.116785                  0.113878\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_187            0.337754  0.114078   0.258506  0.117341                  0.114078\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_145            0.337791  0.114103   0.259123  0.116922                  0.114103\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_715            0.33786   0.114149   0.262742  0.117584                  0.114149\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_61             0.337887  0.114167   0.264254  0.117661                  0.114167\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_656            0.337922  0.114191   0.261924  0.117413                  0.114191\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_206            0.337962  0.114218   0.25663   0.118879                  0.114218\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_31             0.338132  0.114333   0.264538  0.117385                  0.114333\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_541            0.338252  0.114415   0.262148  0.118115                  0.114415\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_313            0.338338  0.114473   0.261478  0.116714                  0.114473\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_751            0.33847   0.114562   0.260901  0.11773                   0.114562\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_205            0.338583  0.114638   0.262863  0.118138                  0.114638\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_286            0.33878   0.114772   0.263291  0.117299                  0.114772\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_477            0.33881   0.114792   0.259551  0.117344                  0.114792\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_385            0.338946  0.114885   0.264995  0.11745                   0.114885\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_700            0.338999  0.11492    0.265451  0.117952                  0.11492\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_36             0.339055  0.114958   0.260293  0.117377                  0.114958\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_717            0.339099  0.114988   0.260945  0.116588                  0.114988\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_733            0.339226  0.115075   0.262213  0.117647                  0.115075\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_4              0.339228  0.115076   0.262814  0.118263                  0.115076\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_525            0.339629  0.115348   0.264     0.118017                  0.115348\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_523            0.339779  0.11545    0.262984  0.118343                  0.11545\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_252            0.339954  0.115569   0.267102  0.118166                  0.115569\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_742            0.340061  0.115641   0.263344  0.11831                   0.115641\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_178            0.340079  0.115654   0.262444  0.118048                  0.115654\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_552            0.34008   0.115655   0.263243  0.118164                  0.115655\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_199            0.340091  0.115662   0.263727  0.117578                  0.115662\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_692            0.340301  0.115805   0.266241  0.118104                  0.115805\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_649            0.340337  0.11583    0.263486  0.118195                  0.11583\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_456            0.340505  0.115944   0.265026  0.118402                  0.115944\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_177            0.340579  0.115994   0.263853  0.118268                  0.115994\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_603            0.34059   0.116001   0.263653  0.117968                  0.116001\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_409            0.340682  0.116064   0.262766  0.117902                  0.116064\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_433            0.340766  0.116122   0.264761  0.118044                  0.116122\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_29             0.34082   0.116158   0.264161  0.118372                  0.116158\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_765            0.34106   0.116322   0.265901  0.118315                  0.116322\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_416            0.341268  0.116464   0.263744  0.118267                  0.116464\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_555            0.341296  0.116483   0.264666  0.118169                  0.116483\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_777            0.341304  0.116488   0.264304  0.118492                  0.116488\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_315            0.341315  0.116496   0.265773  0.118607                  0.116496\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_290            0.34136   0.116527   0.264793  0.118598                  0.116527\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_249   0.341387  0.116545   0.262271  0.116652                  0.116545\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_25             0.341953  0.116932   0.262165  0.118464                  0.116932\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_593            0.34197   0.116943   0.264303  0.118818                  0.116943\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_319            0.341975  0.116947   0.267079  0.119173                  0.116947\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_776            0.341991  0.116958   0.267511  0.11926                   0.116958\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_58    0.34202   0.116978   0.252041  0.110443                  0.116978\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_309            0.342153  0.117068   0.264469  0.118851                  0.117068\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_282            0.342213  0.11711    0.265065  0.118939                  0.11711\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_783            0.342256  0.117139   0.264971  0.118931                  0.117139\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_723            0.342292  0.117164   0.264534  0.118914                  0.117164\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_54             0.342337  0.117195   0.264911  0.119004                  0.117195\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_183            0.342367  0.117215   0.264801  0.122328                  0.117215\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_471            0.342663  0.117418   0.268555  0.119171                  0.117418\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_507            0.342712  0.117451   0.265307  0.11913                   0.117451\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_374            0.342719  0.117456   0.265348  0.118844                  0.117456\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_693            0.342725  0.117461   0.265624  0.118591                  0.117461\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_553            0.342757  0.117482   0.264813  0.119095                  0.117482\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_685            0.342854  0.117549   0.265273  0.119159                  0.117549\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_511            0.342928  0.1176     0.26685   0.119293                  0.1176\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_258            0.34293   0.117601   0.26525   0.11885                   0.117601\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_39             0.342988  0.117641   0.2656    0.118797                  0.117641\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_528            0.343102  0.117719   0.264438  0.119048                  0.117719\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_544            0.343148  0.117751   0.26631   0.118853                  0.117751\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_774            0.343382  0.117911   0.266846  0.119491                  0.117911\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_278            0.343422  0.117938   0.266723  0.11956                   0.117938\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_517            0.343481  0.117979   0.265583  0.118998                  0.117979\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_398            0.343524  0.118009   0.268091  0.119012                  0.118009\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_457            0.343621  0.118076   0.266655  0.119583                  0.118076\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_291            0.343639  0.118088   0.266299  0.119419                  0.118088\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_735            0.343884  0.118256   0.268315  0.119606                  0.118256\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_588            0.344547  0.118712   0.26717   0.11976                   0.118712\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_345            0.344744  0.118849   0.265373  0.1193                    0.118849\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_147            0.344849  0.118921   0.270794  0.119068                  0.118921\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_500            0.345257  0.119203   0.268153  0.120043                  0.119203\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_336            0.345479  0.119356   0.266505  0.119761                  0.119356\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_582            0.34575   0.119543   0.269093  0.119729                  0.119543\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_266            0.346104  0.119788   0.267572  0.119875                  0.119788\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_47    0.346114  0.119795   0.274554  0.124989                  0.119795\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_72             0.346566  0.120108   0.267812  0.119656                  0.120108\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_634            0.347342  0.120646   0.268309  0.119795                  0.120646\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_468            0.348229  0.121263   0.272161  0.120565                  0.121263\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_558            0.348521  0.121467   0.271934  0.120759                  0.121467\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_251   0.349607  0.122225   0.261385  0.11903                   0.122225\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_38    0.350414  0.12279    0.27107   0.126518                  0.12279\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_439            0.352028  0.123924   0.273885  0.121446                  0.123924\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_6     0.352328  0.124135   0.277466  0.124336                  0.124135\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_2     0.354753  0.12585    0.287243  0.128493                  0.12585\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_524            0.355758  0.126563   0.274433  0.127513                  0.126563\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_24    0.356201  0.126879   0.274855  0.123208                  0.126879\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_48    0.362084  0.131105   0.277223  0.130356                  0.131105\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_2     0.367704  0.135206   0.286785  0.127137                  0.135206\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_9     0.368326  0.135664   0.271182  0.120754                  0.135664\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_5     0.369428  0.136477   0.287286  0.132944                  0.136477\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_35    0.370468  0.137246   0.288662  0.128784                  0.137246\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_256   0.373253  0.139318   0.291496  0.134686                  0.139318\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_24    0.381173  0.145293   0.298363  0.135596                  0.145293\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_104   0.393023  0.154467   0.280056  0.125717                  0.154467\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_40    0.410435  0.168456   0.32226   0.148092                  0.168456\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_17    0.41167   0.169472   0.329592  0.149135                  0.169472\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_44    0.424421  0.180133   0.33719   0.152707                  0.180133\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_23    0.432985  0.187476   0.34664   0.156493                  0.187476\n",
      "DeepLearning_1_AutoML_2_20240416_130202                  0.435381  0.189557   0.336326  0.147151                  0.189557\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_18    0.442085  0.195439   0.35415   0.154893                  0.195439\n",
      "DeepLearning_grid_3_AutoML_2_20240416_130202_model_23    0.445473  0.198446   0.363395  0.15183                   0.198446\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_51    0.450439  0.202895   0.362553  0.158427                  0.202895\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_31    0.464606  0.215859   0.372009  0.167371                  0.215859\n",
      "DeepLearning_grid_2_AutoML_2_20240416_130202_model_18    0.607916  0.369562   0.485361  0.207262                  0.369562\n",
      "[875 rows x 6 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = train.columns\n",
    "y = \"logP\"\n",
    "x.remove(y)\n",
    "\n",
    "aml = H2OAutoML(\n",
    "    seed=1, \n",
    "    max_runtime_secs_per_model=300,\n",
    "    keep_cross_validation_predictions=True,\n",
    "    keep_cross_validation_fold_assignment=True,\n",
    "    keep_cross_validation_models=True\n",
    ")\n",
    "aml.train(x=x, y=y, training_frame=train, fold_column=\"fold_id\")\n",
    "\n",
    "lb = aml.leaderboard\n",
    "print(lb.head(rows=lb.nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = h2o.get_model('StackedEnsemble_BestOfFamily_5_AutoML_2_20240416_130202')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeepLearning_grid_1_AutoML_2_20240416_130202_model_31_cv_1',\n",
       " 'DeepLearning_grid_1_AutoML_2_20240416_130202_model_31_cv_2',\n",
       " 'GLM_1_AutoML_2_20240416_130202_cv_1',\n",
       " 'GLM_1_AutoML_2_20240416_130202_cv_2',\n",
       " 'GBM_grid_1_AutoML_2_20240416_130202_model_1_cv_1',\n",
       " 'GBM_grid_1_AutoML_2_20240416_130202_model_1_cv_2',\n",
       " 'XRT_1_AutoML_2_20240416_130202_cv_1',\n",
       " 'XRT_1_AutoML_2_20240416_130202_cv_2',\n",
       " 'DRF_1_AutoML_2_20240416_130202_cv_1',\n",
       " 'DRF_1_AutoML_2_20240416_130202_cv_2']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_models = best_model.base_models\n",
    "base_models_cv = []\n",
    "\n",
    "for base_model in base_models:\n",
    "    base_models_cv.append(base_model + \"_cv_1\")\n",
    "    base_models_cv.append(base_model + \"_cv_2\")\n",
    "\n",
    "base_models_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "DeepLearning_grid_1_AutoML_2_20240416_130202_model_31\n",
      "Parse progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "{'mse': 0.011, 'mae': 0.084, 'r^2': 0.963}\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "{'mse': 0.022, 'mae': 0.107, 'r^2': 0.935}\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "GLM_1_AutoML_2_20240416_130202\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "{'mse': 0.021, 'mae': 0.116, 'r^2': 0.928}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "{'mse': 0.051, 'mae': 0.171, 'r^2': 0.848}\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "GBM_grid_1_AutoML_2_20240416_130202_model_1\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "{'mse': 0.023, 'mae': 0.119, 'r^2': 0.922}\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "{'mse': 0.042, 'mae': 0.151, 'r^2': 0.876}\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "XRT_1_AutoML_2_20240416_130202\n",
      "Parse progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "{'mse': 0.016, 'mae': 0.096, 'r^2': 0.945}\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "████████████████████████████████████████████████████████████████| (done) 100%\n",
      "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "{'mse': 0.02, 'mae': 0.099, 'r^2': 0.94}\n",
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n",
      "DRF_1_AutoML_2_20240416_130202\n",
      "Parse progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "{'mse': 0.009, 'mae': 0.075, 'r^2': 0.968}\n",
      "Parse progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "{'mse': 0.021, 'mae': 0.098, 'r^2': 0.937}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "cv_indices_dict = {0: [], 1: []}\n",
    "index = 0\n",
    "for _, row in train.as_data_frame().iterrows():\n",
    "    cv_indices_dict[row['fold_id']].append(index)\n",
    "    index += 1\n",
    "cv_indices = [[cv_indices_dict[1], cv_indices_dict[0]], [cv_indices_dict[0], cv_indices_dict[1]]]\n",
    "\n",
    "for base_model in base_models:\n",
    "    print(\"-\"*30)\n",
    "    print(\"-\"*30)\n",
    "    print(\"-\"*30)\n",
    "    print(base_model)\n",
    "    for cv_idx in range(len(cv_indices)):\n",
    "        base_model_cv = base_model + f\"_cv_{cv_idx + 1}\"\n",
    "        cv_indexes = cv_indices[cv_idx]\n",
    "        \n",
    "        train_idx = cv_indexes[0]\n",
    "        test_idx = cv_indexes[1]\n",
    "\n",
    "        train_h2o_cv = h2o.H2OFrame(train_df.iloc[train_idx])\n",
    "        test_h2o_cv = h2o.H2OFrame(train_df.iloc[test_idx])\n",
    "\n",
    "        model_cv = h2o.get_model(base_model_cv)\n",
    "        preds = model_cv.predict(train_h2o_cv)\n",
    "\n",
    "        true = train_h2o_cv.as_data_frame()['logP']\n",
    "        predicted_values = preds.as_data_frame()['predict']\n",
    "\n",
    "        print(calculate_metrics(true, predicted_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mse': 0.024, 'mae': 0.115, 'r^2': 0.925}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = aml.get_best_model()\n",
    "preds = best_model.predict(train)\n",
    "true = train.as_data_frame()['logP']\n",
    "predicted_values = preds.as_data_frame()['predict']\n",
    "\n",
    "calculate_metrics(true, predicted_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "c:\\work\\DrugDiscovery\\drug-discovery-venv\\Lib\\site-packages\\h2o\\frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mse': 0.018, 'mae': 0.117, 'r^2': 0.933}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = aml.get_best_model()\n",
    "preds = best_model.predict(test)\n",
    "true = test.as_data_frame()['logP']\n",
    "predicted_values = preds.as_data_frame()['predict']\n",
    "\n",
    "calculate_metrics(true, predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_BestOfFamily_5_AutoML_2_20240416_130202\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-54.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-54 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-54 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-54 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-54 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-54 .h2o-table th,\n",
       "#h2o-table-54 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-54 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-54\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary for Stacked Ensemble: </caption>\n",
       "    <thead><tr><th>key</th>\n",
       "<th>value</th></tr></thead>\n",
       "    <tbody><tr><td>Stacking strategy</td>\n",
       "<td>cross_validation</td></tr>\n",
       "<tr><td>Number of base models (used / total)</td>\n",
       "<td>5/5</td></tr>\n",
       "<tr><td># GBM base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># DeepLearning base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># GLM base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># DRF base models (used / total)</td>\n",
       "<td>2/2</td></tr>\n",
       "<tr><td>Metalearner algorithm</td>\n",
       "<td>GLM</td></tr>\n",
       "<tr><td>Metalearner fold assignment scheme</td>\n",
       "<td>AUTO</td></tr>\n",
       "<tr><td>Metalearner nfolds</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>Metalearner fold_column</td>\n",
       "<td>fold_id</td></tr>\n",
       "<tr><td>Custom metalearner hyperparameters</td>\n",
       "<td>None</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02385476554595543\n",
       "RMSE: 0.15444988036886087\n",
       "MAE: 0.11513280156833935\n",
       "RMSLE: 0.05771712529610889\n",
       "Mean Residual Deviance: 0.02385476554595543\n",
       "R^2: 0.925011257718907\n",
       "Null degrees of freedom: 146\n",
       "Residual degrees of freedom: 141\n",
       "Null deviance: 46.762359636743106\n",
       "Residual deviance: 3.506650535255448\n",
       "AIC: -117.99044768677385</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.05894898299905989\n",
       "RMSE: 0.2427941164836164\n",
       "MAE: 0.18862879537799285\n",
       "RMSLE: 0.08590528827961759\n",
       "Mean Residual Deviance: 0.05894898299905989\n",
       "R^2: 0.8146906920827617\n",
       "Null degrees of freedom: 146\n",
       "Residual degrees of freedom: 141\n",
       "Null deviance: 46.77227619874058\n",
       "Residual deviance: 8.665500500861803\n",
       "AIC: 14.998741863601854</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-55.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-55 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-55 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-55 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-55 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-55 .h2o-table th,\n",
       "#h2o-table-55 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-55 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-55\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th></tr></thead>\n",
       "    <tbody><tr><td>mae</td>\n",
       "<td>0.1876857</td>\n",
       "<td>0.0276561</td>\n",
       "<td>0.2072415</td>\n",
       "<td>0.1681298</td></tr>\n",
       "<tr><td>mean_residual_deviance</td>\n",
       "<td>0.0585603</td>\n",
       "<td>0.0240600</td>\n",
       "<td>0.0755732</td>\n",
       "<td>0.0415473</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0585603</td>\n",
       "<td>0.0240600</td>\n",
       "<td>0.0755732</td>\n",
       "<td>0.0415473</td></tr>\n",
       "<tr><td>null_deviance</td>\n",
       "<td>23.386139</td>\n",
       "<td>2.5729854</td>\n",
       "<td>25.205513</td>\n",
       "<td>21.566763</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8181612</td>\n",
       "<td>0.0609421</td>\n",
       "<td>0.7750686</td>\n",
       "<td>0.8612538</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>4.3297005</td>\n",
       "<td>1.892632</td>\n",
       "<td>5.6679935</td>\n",
       "<td>2.9914076</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.2393687</td>\n",
       "<td>0.0502571</td>\n",
       "<td>0.2749059</td>\n",
       "<td>0.2038316</td></tr>\n",
       "<tr><td>rmsle</td>\n",
       "<td>0.0839708</td>\n",
       "<td>0.0222748</td>\n",
       "<td>0.0997214</td>\n",
       "<td>0.0682201</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_BestOfFamily_5_AutoML_2_20240416_130202\n",
       "\n",
       "\n",
       "Model Summary for Stacked Ensemble: \n",
       "key                                        value\n",
       "-----------------------------------------  ----------------\n",
       "Stacking strategy                          cross_validation\n",
       "Number of base models (used / total)       5/5\n",
       "# GBM base models (used / total)           1/1\n",
       "# DeepLearning base models (used / total)  1/1\n",
       "# GLM base models (used / total)           1/1\n",
       "# DRF base models (used / total)           2/2\n",
       "Metalearner algorithm                      GLM\n",
       "Metalearner fold assignment scheme         AUTO\n",
       "Metalearner nfolds                         0\n",
       "Metalearner fold_column                    fold_id\n",
       "Custom metalearner hyperparameters         None\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02385476554595543\n",
       "RMSE: 0.15444988036886087\n",
       "MAE: 0.11513280156833935\n",
       "RMSLE: 0.05771712529610889\n",
       "Mean Residual Deviance: 0.02385476554595543\n",
       "R^2: 0.925011257718907\n",
       "Null degrees of freedom: 146\n",
       "Residual degrees of freedom: 141\n",
       "Null deviance: 46.762359636743106\n",
       "Residual deviance: 3.506650535255448\n",
       "AIC: -117.99044768677385\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.05894898299905989\n",
       "RMSE: 0.2427941164836164\n",
       "MAE: 0.18862879537799285\n",
       "RMSLE: 0.08590528827961759\n",
       "Mean Residual Deviance: 0.05894898299905989\n",
       "R^2: 0.8146906920827617\n",
       "Null degrees of freedom: 146\n",
       "Residual degrees of freedom: 141\n",
       "Null deviance: 46.77227619874058\n",
       "Residual deviance: 8.665500500861803\n",
       "AIC: 14.998741863601854\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                        mean       sd         cv_1_valid    cv_2_valid\n",
       "----------------------  ---------  ---------  ------------  ------------\n",
       "mae                     0.187686   0.0276561  0.207241      0.16813\n",
       "mean_residual_deviance  0.0585603  0.02406    0.0755732     0.0415473\n",
       "mse                     0.0585603  0.02406    0.0755732     0.0415473\n",
       "null_deviance           23.3861    2.57299    25.2055       21.5668\n",
       "r2                      0.818161   0.0609421  0.775069      0.861254\n",
       "residual_deviance       4.3297     1.89263    5.66799       2.99141\n",
       "rmse                    0.239369   0.0502571  0.274906      0.203832\n",
       "rmsle                   0.0839708  0.0222748  0.0997214     0.0682201\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = h2o.save_model(model=best_model, path=r\"C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\ml_part\\h2o_model\\models\\16.04.24_proper_train_crossval\", force=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drug-discovery-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
