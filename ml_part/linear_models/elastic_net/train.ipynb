{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PKA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MINMAX scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PKA_FEATURES = ['RPCS', 'PBF', 'mol_weight', 'dipole_moment', 'PPSA5',\n",
    "                'avg_atoms_in_cycle', 'nHRing', 'cis/trans', 'FPSA3', 'nF', 'chirality',\n",
    "                'sasa', 'PNSA5', 'GeomShapeIndex', 'TASA', 'mol_num_cycles',\n",
    "                'f_freedom', 'nFRing', 'identificator', 'nO', 'nARing', 'nC', 'nFHRing',\n",
    "                'f_to_fg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\pKA_logP_minmaxscaler\\pKa\\train_pka_minmax.csv', index_col=0)\n",
    "\n",
    "y = train['pKa']\n",
    "X=train[PKA_FEATURES]\n",
    "\n",
    "test = pd.read_csv(r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\pKA_logP_minmaxscaler\\pKa\\test_pka_minmax.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_indices_dict = {0: [], 1: []}\n",
    "index = 0\n",
    "for _, row in train.iterrows():\n",
    "    cv_indices_dict[row['fold_id']].append(index)\n",
    "    index += 1\n",
    "cv_indices = [[cv_indices_dict[0], cv_indices_dict[1]], [cv_indices_dict[1], cv_indices_dict[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========pKa=========\n",
      "R^2 = 0.88\n",
      "MAE =  0.71\n",
      "MSE =  0.723\n",
      "=========pKa=========\n",
      "R^2 = 0.936\n",
      "MAE =  0.509\n",
      "MSE =  0.415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "train = pd.read_csv(r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\pKA_logP_minmaxscaler\\pKa\\train_pka_minmax.csv', index_col=0)\n",
    "y = train['pKa']\n",
    "X=train.drop(['pKa', 'fold_id'], axis=1)\n",
    "\n",
    "regr = ElasticNetCV(cv=cv_indices, random_state=0, max_iter=20000, n_alphas=1000)\n",
    "regr.fit(X, y)\n",
    "test = pd.read_csv(r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\pKA_logP_minmaxscaler\\pKa\\test_pka_minmax.csv', index_col=0)\n",
    "\n",
    "def metrics(test, feature):\n",
    "    y_pred = regr.predict(test.drop([feature], axis=1))\n",
    "    r2 = r2_score(y_pred=y_pred, y_true = test[feature])\n",
    "    print(f'=========%s========='%(feature))\n",
    "    print('R^2 = '+str(round(r2, 3)))\n",
    "    print('MAE = ', round(mae(y_true = test[feature], y_pred=y_pred), 3))\n",
    "    print('MSE = ', round(mse(y_true = test[feature], y_pred=y_pred), 3))\n",
    "metrics(test, 'pKa')\n",
    "regr.score(X, y)\n",
    "metrics(train.drop('fold_id', axis=1), 'pKa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.688, 'mae': 0.635, 'r^2': 0.894}\n",
      "R^2 (Cross-Validated): 0.8939557068132683\n",
      "MAE (Cross-Validated): 0.6348993568621347\n",
      "=========pKa=========\n",
      "R^2 = 0.88\n",
      "MAE =  0.71\n",
      "MSE =  0.723\n",
      "=========pKa=========\n",
      "R^2 = 0.936\n",
      "MAE =  0.509\n",
      "MSE =  0.415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "\n",
    "def calculate_metrics(true_values, pred_values):\n",
    "    mse = round(mean_squared_error(true_values, pred_values),3)\n",
    "    mae = round(mean_absolute_error(true_values, pred_values),3)\n",
    "    r_score = round(r2_score(true_values, pred_values),3)\n",
    "\n",
    "    return {\"mse\": mse,\n",
    "            \"mae\": mae,\n",
    "            \"r^2\": r_score,}\n",
    "\n",
    "# Initialize ElasticNetCV\n",
    "model = ElasticNetCV(cv=2, random_state=0, max_iter=20000, n_alphas=1000)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get cross-validated predictions\n",
    "y_pred_cv = cross_val_predict(model, X, y, cv=cv_indices)\n",
    "\n",
    "print(calculate_metrics(true_values=y, pred_values=y_pred_cv))\n",
    "\n",
    "def metrics(test, feature):\n",
    "    y_pred = model.predict(test.drop([feature], axis=1))\n",
    "    r2 = r2_score(y_pred=y_pred, y_true = test[feature])\n",
    "    print(f'=========%s========='%(feature))\n",
    "    print('R^2 = '+str(round(r2, 3)))\n",
    "    print('MAE = ', round(mae(y_true = test[feature], y_pred=y_pred), 3))\n",
    "    print('MSE = ', round(mse(y_true = test[feature], y_pred=y_pred), 3))\n",
    "metrics(test, 'pKa')\n",
    "model.score(X, y)\n",
    "metrics(train.drop('fold_id', axis=1), 'pKa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MINMAX scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\pKA_logP_minmaxscaler\\pKa\\train_pka_standart_scaler.csv', index_col=0)\n",
    "\n",
    "y = train['pKa']\n",
    "X=train[PKA_FEATURES]\n",
    "\n",
    "test = pd.read_csv(r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\pKA_logP_minmaxscaler\\pKa\\test_pka_standart_scaler.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_indices_dict = {0: [], 1: []}\n",
    "index = 0\n",
    "for _, row in train.iterrows():\n",
    "    cv_indices_dict[row['fold_id']].append(index)\n",
    "    index += 1\n",
    "cv_indices = [[cv_indices_dict[0], cv_indices_dict[1]], [cv_indices_dict[1], cv_indices_dict[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.611, 'mae': 0.597, 'r^2': 0.906}\n",
      "=========pKa=========\n",
      "R^2 = 0.883\n",
      "MAE =  0.66\n",
      "MSE =  0.706\n",
      "=========pKa=========\n",
      "R^2 = 0.943\n",
      "MAE =  0.479\n",
      "MSE =  0.373\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "\n",
    "def calculate_metrics(true_values, pred_values):\n",
    "    mse = round(mean_squared_error(true_values, pred_values),3)\n",
    "    mae = round(mean_absolute_error(true_values, pred_values),3)\n",
    "    r_score = round(r2_score(true_values, pred_values),3)\n",
    "\n",
    "    return {\"mse\": mse,\n",
    "            \"mae\": mae,\n",
    "            \"r^2\": r_score,}\n",
    "\n",
    "# Initialize ElasticNetCV\n",
    "model = ElasticNetCV(cv=2, random_state=0, max_iter=20000, n_alphas=1000)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get cross-validated predictions\n",
    "y_pred_cv = cross_val_predict(model, X, y, cv=cv_indices)\n",
    "\n",
    "print(calculate_metrics(true_values=y, pred_values=y_pred_cv))\n",
    "\n",
    "def metrics(test, feature):\n",
    "    y_pred = model.predict(test.drop([feature], axis=1))\n",
    "    r2 = r2_score(y_pred=y_pred, y_true = test[feature])\n",
    "    print(f'=========%s========='%(feature))\n",
    "    print('R^2 = '+str(round(r2, 3)))\n",
    "    print('MAE = ', round(mean_absolute_error(y_true = test[feature], y_pred=y_pred), 3))\n",
    "    print('MSE = ', round(mean_squared_error(y_true = test[feature], y_pred=y_pred), 3))\n",
    "metrics(test, 'pKa')\n",
    "model.score(X, y)\n",
    "metrics(train.drop('fold_id', axis=1), 'pKa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\pKA_logP_minmaxscaler\\logP\\train_logp_minmax.csv', index_col=0)\n",
    "\n",
    "y = train['logP']\n",
    "X = train.drop(['fold_id', 'logP'], axis=1)\n",
    "\n",
    "test = pd.read_csv(r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\pKA_logP_minmaxscaler\\logP\\test_logp_minmax.csv', index_col=0)\n",
    "\n",
    "cv_indices_dict = {0: [], 1: []}\n",
    "index = 0\n",
    "for _, row in train.iterrows():\n",
    "    cv_indices_dict[row['fold_id']].append(index)\n",
    "    index += 1\n",
    "cv_indices = [[cv_indices_dict[0], cv_indices_dict[1]], [cv_indices_dict[1], cv_indices_dict[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.064, 'mae': 0.193, 'r^2': 0.799}\n",
      "=========logP=========\n",
      "R^2 = 0.91\n",
      "MAE =  0.121\n",
      "MSE =  0.024\n",
      "=========logP=========\n",
      "R^2 = 0.877\n",
      "MAE =  0.151\n",
      "MSE =  0.039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "\n",
    "def calculate_metrics(true_values, pred_values):\n",
    "    mse = round(mean_squared_error(true_values, pred_values),3)\n",
    "    mae = round(mean_absolute_error(true_values, pred_values),3)\n",
    "    r_score = round(r2_score(true_values, pred_values),3)\n",
    "\n",
    "    return {\"mse\": mse,\n",
    "            \"mae\": mae,\n",
    "            \"r^2\": r_score,}\n",
    "\n",
    "# Initialize ElasticNetCV\n",
    "model = ElasticNetCV(cv=2, random_state=0, max_iter=20000, n_alphas=1000)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get cross-validated predictions\n",
    "y_pred_cv = cross_val_predict(model, X, y, cv=cv_indices)\n",
    "\n",
    "print(calculate_metrics(true_values=y, pred_values=y_pred_cv))\n",
    "\n",
    "def metrics(test, feature):\n",
    "    y_pred = model.predict(test.drop([feature], axis=1))\n",
    "    r2 = r2_score(y_pred=y_pred, y_true = test[feature])\n",
    "    print(f'=========%s========='%(feature))\n",
    "    print('R^2 = '+str(round(r2, 3)))\n",
    "    print('MAE = ', round(mae(y_true = test[feature], y_pred=y_pred), 3))\n",
    "    print('MSE = ', round(mse(y_true = test[feature], y_pred=y_pred), 3))\n",
    "metrics(test, 'logP')\n",
    "model.score(X, y)\n",
    "metrics(train.drop('fold_id', axis=1), 'logP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========logP=========\n",
      "R^2 = 0.916\n",
      "MAE =  0.12\n",
      "MSE =  0.022\n",
      "=========logP=========\n",
      "R^2 = 0.864\n",
      "MAE =  0.156\n",
      "MSE =  0.043\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 74 is out of bounds for axis 0 with size 73",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m metrics(train\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_id\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Get cross-validated predictions\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m y_pred_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(calculate_metrics(true_values\u001b[38;5;241m=\u001b[39my, pred_values\u001b[38;5;241m=\u001b[39my_pred_cv))\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1293\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m-> 1293\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1306\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1307\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1378\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, fit_params, method)\u001b[0m\n\u001b[0;32m   1376\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[0;32m   1380\u001b[0m predictions \u001b[38;5;241m=\u001b[39m func(X_test)\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1751\u001b[0m, in \u001b[0;36mLinearModelCV.fit\u001b[1;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# We do a double for loop folded in one, in order to be able to\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# iterate in parallel on l1_ratio and folds\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m jobs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1734\u001b[0m     delayed(_path_residuals)(\n\u001b[0;32m   1735\u001b[0m         X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m folds\n\u001b[0;32m   1750\u001b[0m )\n\u001b[1;32m-> 1751\u001b[0m mse_paths \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1756\u001b[0m mse_paths \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(mse_paths, (n_l1_ratio, \u001b[38;5;28mlen\u001b[39m(folds), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# The mean is computed over folds.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\dgl-cuda-env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1374\u001b[0m, in \u001b[0;36m_path_residuals\u001b[1;34m(X, y, sample_weight, train, test, fit_intercept, path, path_params, alphas, l1_ratio, X_order, dtype)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_path_residuals\u001b[39m(\n\u001b[0;32m   1317\u001b[0m     X,\n\u001b[0;32m   1318\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1328\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1329\u001b[0m ):\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the MSE for the models computed by 'path'.\u001b[39;00m\n\u001b[0;32m   1331\u001b[0m \n\u001b[0;32m   1332\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;124;03m        avoid memory copies.\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1375\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m y[train]\n\u001b[0;32m   1376\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m X[test]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 74 is out of bounds for axis 0 with size 73"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "\n",
    "def calculate_metrics(true_values, pred_values):\n",
    "    mse = round(mean_squared_error(true_values, pred_values),3)\n",
    "    mae = round(mean_absolute_error(true_values, pred_values),3)\n",
    "    r_score = round(r2_score(true_values, pred_values),3)\n",
    "\n",
    "    return {\"mse\": mse,\n",
    "            \"mae\": mae,\n",
    "            \"r^2\": r_score,}\n",
    "\n",
    "# Initialize ElasticNetCV\n",
    "model = ElasticNetCV(cv=cv_indices, random_state=0, max_iter=20000, n_alphas=1000)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "def metrics(test, feature):\n",
    "    y_pred = model.predict(test.drop([feature], axis=1))\n",
    "    r2 = r2_score(y_pred=y_pred, y_true = test[feature])\n",
    "    print(f'=========%s========='%(feature))\n",
    "    print('R^2 = '+str(round(r2, 3)))\n",
    "    print('MAE = ', round(mae(y_true = test[feature], y_pred=y_pred), 3))\n",
    "    print('MSE = ', round(mse(y_true = test[feature], y_pred=y_pred), 3))\n",
    "metrics(test, 'logP')\n",
    "model.score(X, y)\n",
    "metrics(train.drop('fold_id', axis=1), 'logP')\n",
    "\n",
    "# Get cross-validated predictions\n",
    "y_pred_cv = cross_val_predict(model, X, y, cv=2)\n",
    "\n",
    "print(calculate_metrics(true_values=y, pred_values=y_pred_cv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STANDART SCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\pKA_logP_minmaxscaler\\logP\\train_logp_standart_scaler.csv', index_col=0)\n",
    "\n",
    "y = train['logP']\n",
    "X = train.drop(['fold_id', 'logP'], axis=1)\n",
    "\n",
    "test = pd.read_csv(r'C:\\work\\DrugDiscovery\\main_git\\XAI_Chem\\data\\pKA_logP_minmaxscaler\\logP\\test_logp_standart_scaler.csv', index_col=0)\n",
    "\n",
    "cv_indices_dict = {0: [], 1: []}\n",
    "index = 0\n",
    "for _, row in train.iterrows():\n",
    "    cv_indices_dict[row['fold_id']].append(index)\n",
    "    index += 1\n",
    "cv_indices = [[cv_indices_dict[0], cv_indices_dict[1]], [cv_indices_dict[1], cv_indices_dict[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.058, 'mae': 0.185, 'r^2': 0.819}\n",
      "=========logP=========\n",
      "R^2 = 0.909\n",
      "MAE =  0.121\n",
      "MSE =  0.024\n",
      "=========logP=========\n",
      "R^2 = 0.877\n",
      "MAE =  0.15\n",
      "MSE =  0.039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "\n",
    "def calculate_metrics(true_values, pred_values):\n",
    "    mse = round(mean_squared_error(true_values, pred_values),3)\n",
    "    mae = round(mean_absolute_error(true_values, pred_values),3)\n",
    "    r_score = round(r2_score(true_values, pred_values),3)\n",
    "\n",
    "    return {\"mse\": mse,\n",
    "            \"mae\": mae,\n",
    "            \"r^2\": r_score,}\n",
    "\n",
    "# Initialize ElasticNetCV\n",
    "model = ElasticNetCV(cv=2, random_state=0, max_iter=20000, n_alphas=1000)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get cross-validated predictions\n",
    "y_pred_cv = cross_val_predict(model, X, y, cv=cv_indices)\n",
    "\n",
    "print(calculate_metrics(true_values=y, pred_values=y_pred_cv))\n",
    "\n",
    "def metrics(test, feature):\n",
    "    y_pred = model.predict(test.drop([feature], axis=1))\n",
    "    r2 = r2_score(y_pred=y_pred, y_true = test[feature])\n",
    "    print(f'=========%s========='%(feature))\n",
    "    print('R^2 = '+str(round(r2, 3)))\n",
    "    print('MAE = ', round(mean_absolute_error(y_true = test[feature], y_pred=y_pred), 3))\n",
    "    print('MSE = ', round(mean_squared_error(y_true = test[feature], y_pred=y_pred), 3))\n",
    "metrics(test, 'logP')\n",
    "model.score(X, y)\n",
    "metrics(train.drop('fold_id', axis=1), 'logP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl-cuda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
